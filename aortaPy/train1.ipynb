{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import DataLoader\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import numpy as np\n",
    "from config import Config\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/train\n",
      "/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/test\n",
      "/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/val\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/train\"\n",
    "val_dir = \"/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/val\"\n",
    "test_dir = \"/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/test\"\n",
    "csv_path = \"/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/df.csv\"\n",
    "\n",
    "dataset_train = DataLoader.Dataset()\n",
    "dataset_test = DataLoader.Dataset()\n",
    "dataset_val = DataLoader.Dataset()\n",
    "\n",
    "dataset_train.load_dataset(train_dir)\n",
    "dataset_test.load_dataset(test_dir)\n",
    "dataset_val.load_dataset(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['35_event',\n",
       " '35_control',\n",
       " '34_event',\n",
       " '34_control',\n",
       " '33_event',\n",
       " '33_control',\n",
       " '38_control',\n",
       " '38_event',\n",
       " '36_event',\n",
       " '36_control',\n",
       " '37_event',\n",
       " '37_control',\n",
       " '39_control',\n",
       " '39_event',\n",
       " '41_control',\n",
       " '41_event',\n",
       " '40_control',\n",
       " '40_event']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_case_attributes(csv_path):\n",
    "    df = pd.read_csv(csv_path,header=0)\n",
    "    df.drop([\"tchol\",'hdl','ldl','trig','hypotension'], axis=1, inplace=True)\n",
    "    df['ane_diam'].fillna(0,inplace=True)\n",
    "    df.fillna(method='ffill',inplace=True)\n",
    "    small = LabelBinarizer().fit(df[\"smallbin\"])\n",
    "    df['smallbin']=small.transform(df['smallbin'])\n",
    "    dia = LabelBinarizer().fit(df[\"diabetes\"])\n",
    "    hbp = LabelBinarizer().fit(df[\"HBP\"])\n",
    "    df['diabetes']=dia.transform(df['diabetes'])\n",
    "    df['HBP']=hbp.transform(df['HBP'])\n",
    "    #cs = MinMaxScaler()\n",
    "    #df[df.columns[2:]] = cs.fit_transform(df[df.columns[2:]])\n",
    "    #df[df.columns[2:]] = df[df.columns[2:]].astype(np.float32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    for i in dataset_train.case_id:\n",
    "        img, class_id = dataset_train.load_case_image(i, IMG_ID)\n",
    "        det = augment.to_deterministic()\n",
    "        img = det.augment_image(img)\n",
    "        yield img, class_id\n",
    "\n",
    "def test_generator():\n",
    "    for i in dataset_test.case_id:\n",
    "        img, class_id = dataset_test.load_case_image(i, IMG_ID)[0]\n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  group  sex  age    score2  smallbin        bmi  time_onset  ane_diam  \\\n",
      "0    1      1    0   71 -0.657735         1  22.656250         7.0     5.000   \n",
      "1    1      0    0   69 -0.260601         1  27.548209        48.0     5.640   \n",
      "2    2      1    1   33 -2.010208         0  25.380000        12.0     4.700   \n",
      "3    2      0    1   28 -1.937681         0  29.069767        10.0     0.000   \n",
      "4    3      0    1   50 -0.880417         0  23.875115       168.0     0.000   \n",
      "5    3      1    1   49 -0.817507         1  27.379665        24.0     5.100   \n",
      "6    4      0    1   47 -1.704438         0  40.000000         5.0     0.000   \n",
      "7    4      1    1   53 -1.705023         1  19.390582        24.0     4.000   \n",
      "8    5      1    1   50 -0.012975         0  31.141869        24.0     4.980   \n",
      "9    5      0    1   50 -0.025385         0  26.423570         8.0     5.600   \n",
      "10   6      0    1   46 -1.950741         0  29.410759         4.0     4.400   \n",
      "11   6      1    1   50 -1.963092         0  24.221453        24.0     4.500   \n",
      "12   7      0    1   53 -1.819756         0  21.604938       120.0     6.000   \n",
      "13   7      1    1   49 -1.860024         0  24.910767        20.0     4.210   \n",
      "14   8      1    1   50 -1.740890         0  27.681661        24.0     6.640   \n",
      "15   8      0    1   48 -1.806499         0  27.681661        24.0     0.000   \n",
      "16   9      0    0   61 -0.816806         1  28.934069        48.0     0.000   \n",
      "17   9      1    0   58 -0.670273         1  24.034610         8.0     4.700   \n",
      "18  10      1    1   63 -2.164651         0  23.836735         4.0     4.630   \n",
      "19  10      0    1   58 -2.213810         0  27.755102         4.0     4.400   \n",
      "20  11      0    1   43 -2.173324         1  28.734694        24.0     0.000   \n",
      "21  11      1    1   41 -2.191658         0  20.987654        24.0     4.300   \n",
      "22  12      0    1   59 -1.230815         1  24.221453         8.0     4.600   \n",
      "23  12      1    1   62 -0.559796         1  28.400548        10.0     4.100   \n",
      "24  13      0    0   62 -1.383597         1  27.239224        96.0     0.000   \n",
      "25  13      1    0   65 -1.221590         1  25.390625        18.0     3.900   \n",
      "26  14      0    1   54 -1.901623         0  21.718066        18.0     6.000   \n",
      "27  14      1    1   47 -1.906157         0  25.351541        24.0     5.336   \n",
      "28  15      0    1   59 -1.591389         0  21.971336        24.0     5.600   \n",
      "29  15      1    1   57 -1.598571         0  24.337480        96.0     4.400   \n",
      "..  ..    ...  ...  ...       ...       ...        ...         ...       ...   \n",
      "52  27      0    1   52 -1.140367         1  22.204082        96.0     4.950   \n",
      "53  27      1    1   51  0.563989         1  26.122449        24.0     4.300   \n",
      "54  28      0    1   41 -1.097852         0  26.729928        24.0     4.000   \n",
      "55  28      1    1   39 -1.121745         1  27.777778         5.0     4.360   \n",
      "56  29      0    0   57 -2.288408         1  29.903029        96.0     4.540   \n",
      "57  29      1    0   63 -1.815946         1  27.055151        13.0     4.250   \n",
      "58  30      0    1   53 -1.641087         0  30.421850       120.0     4.100   \n",
      "59  30      1    1   52 -1.648182         0  23.938990        11.0     4.500   \n",
      "60  31      1    1   52 -1.589733         0  26.729928        12.0     0.000   \n",
      "61  31      0    1   48 -1.434553         0  31.095278        24.0     5.130   \n",
      "62  32      0    1   43 -0.956578         0  29.983588        14.0     0.000   \n",
      "63  32      1    1   37 -0.707165         0  24.618104        24.0     0.000   \n",
      "64  33      0    0   53 -2.106903         1  22.038567        72.0     5.480   \n",
      "65  33      1    0   50 -1.852128         0  22.862369        15.0     4.700   \n",
      "66  34      0    1   68 -1.610389         1  29.384757       120.0     4.190   \n",
      "67  34      1    1   68 -0.867844         0  22.204082        48.0     5.200   \n",
      "68  35      1    1   55 -2.344058         0  20.619254        72.0     0.000   \n",
      "69  35      0    1   59 -2.271741         0  27.732300        48.0     5.050   \n",
      "70  36      1    1   50 -1.698870         1  28.400548        24.0     0.000   \n",
      "71  36      0    1   52 -1.257730         1  28.731747       240.0     4.000   \n",
      "72  37      1    1   54 -1.707943         1  26.573129        24.0     4.400   \n",
      "73  37      0    1   51 -1.747033         0  26.122449        24.0     5.000   \n",
      "74  38      1    1   43 -2.120811         0  29.410000         8.0     6.400   \n",
      "75  38      0    1   41 -1.951066         0  31.887755        18.0     3.910   \n",
      "76  39      0    1   57 -2.013845         0  27.005131       168.0     4.700   \n",
      "77  39      1    1   58 -1.378944         1  24.221453        48.0     4.800   \n",
      "78  40      1    0   55 -2.391192         1  20.253848        24.0     0.000   \n",
      "79  40      0    0   49 -2.286890         1  27.335640        24.0     6.810   \n",
      "80  41      1    0   58 -1.940001         1  27.053803        12.0     0.000   \n",
      "81  41      0    0   64 -1.384039         1  27.343750        48.0     4.400   \n",
      "\n",
      "    diabetes  hs_cad  hyperlipidemia  HBP    SBP    DBP  ECG  kidney_failure  \\\n",
      "0          1     0.0             0.0    1  150.0   90.0    1               0   \n",
      "1          1     0.0             1.0    1  116.0   78.0    1               0   \n",
      "2          0     0.0             0.0    1  116.0   78.0    0               0   \n",
      "3          0     0.0             0.0    1  140.0   80.0    0               0   \n",
      "4          0     0.0             0.0    1  120.0   70.0    1               0   \n",
      "5          0     0.0             0.0    1  129.0   45.0    1               0   \n",
      "6          0     0.0             0.0    0  150.0   80.0    0               0   \n",
      "7          0     0.0             0.0    1  134.0   66.0    0               0   \n",
      "8          0     0.0             0.0    1  105.0   50.0    1               0   \n",
      "9          0     0.0             0.0    1  121.0   51.0    0               0   \n",
      "10         0     0.0             1.0    1  127.0   50.0    1               0   \n",
      "11         0     0.0             0.0    1  176.0   94.0    1               0   \n",
      "12         0     0.0             0.0    1  114.0   57.0    1               0   \n",
      "13         0     0.0             0.0    1  140.0   60.0    1               0   \n",
      "14         0     0.0             1.0    1  102.0   70.0    1               0   \n",
      "15         0     0.0             1.0    1  102.0   70.0    1               0   \n",
      "16         1     0.0             0.0    1  143.0   96.0    1               0   \n",
      "17         0     0.0             0.0    0   67.0   51.0    1               0   \n",
      "18         0     0.0             0.0    1  200.0  101.0    1               0   \n",
      "19         0     0.0             1.0    1  120.0   60.0    1               0   \n",
      "20         0     0.0             0.0    0  143.0   79.0    1               0   \n",
      "21         0     0.0             0.0    1  138.0   70.0    1               0   \n",
      "22         0     0.0             0.0    0  140.0   80.0    0               0   \n",
      "23         0     0.0             0.0    0  165.0   86.0    1               0   \n",
      "24         0     0.0             0.0    0  132.0   79.0    0               0   \n",
      "25         0     0.0             0.0    1  104.0   80.0    1               0   \n",
      "26         0     0.0             0.0    1  120.0   80.0    1               0   \n",
      "27         0     0.0             1.0    1  177.0   96.0    1               0   \n",
      "28         0     0.0             0.0    1  119.0   70.0    1               0   \n",
      "29         0     0.0             0.0    1  132.0   71.0    1               0   \n",
      "..       ...     ...             ...  ...    ...    ...  ...             ...   \n",
      "52         0     0.0             0.0    0   99.0   61.0    1               0   \n",
      "53         0     0.0             0.0    1  141.0   76.0    1               0   \n",
      "54         0     0.0             0.0    1  108.0   62.0    1               0   \n",
      "55         0     0.0             0.0    1   84.0   50.0    1               0   \n",
      "56         0     0.0             1.0    1  170.0   83.0    0               0   \n",
      "57         0     0.0             0.0    1   97.0   51.0    0               0   \n",
      "58         0     0.0             1.0    1  140.0   78.0    1               0   \n",
      "59         0     0.0             0.0    1  125.0   71.0    0               0   \n",
      "60         0     0.0             0.0    1  150.0   80.0    1               0   \n",
      "61         0     0.0             1.0    1  158.0  101.0    1               0   \n",
      "62         0     0.0             0.0    1  155.0   89.0    1               1   \n",
      "63         0     0.0             0.0    1  123.0   66.0    1               0   \n",
      "64         0     0.0             0.0    1   99.0   75.0    1               0   \n",
      "65         0     0.0             0.0    1  115.0   67.0    1               0   \n",
      "66         0     0.0             0.0    1  140.0   85.0    1               0   \n",
      "67         0     0.0             0.0    1  122.0   71.0    1               0   \n",
      "68         0     0.0             0.0    1  127.0   86.0    0               0   \n",
      "69         0     0.0             0.0    1  164.0   94.0    0               0   \n",
      "70         0     0.0             1.0    1  150.0   70.0    1               0   \n",
      "71         0     0.0             1.0    1  113.0   62.0    1               0   \n",
      "72         0     0.0             0.0    0  128.0   64.0    0               0   \n",
      "73         0     0.0             0.0    0  110.0   70.0    1               0   \n",
      "74         0     0.0             0.0    1  110.0   70.0    1               0   \n",
      "75         0     1.0             0.0    1  168.0   25.0    1               0   \n",
      "76         0     0.0             0.0    1  128.0   70.0    1               0   \n",
      "77         0     0.0             0.0    0  125.0   76.0    1               0   \n",
      "78         0     0.0             0.0    1  130.0   75.0    0               0   \n",
      "79         0     1.0             0.0    1  143.0   90.0    1               0   \n",
      "80         0     0.0             0.0    0  130.0   80.0    1               0   \n",
      "81         1     0.0             0.0    1  132.0   84.0    1               0   \n",
      "\n",
      "    ln_ddimer  limb_ischemia  tamponade_presurgbin  \n",
      "0   10.250758              0                     0  \n",
      "1    7.795647              0                     1  \n",
      "2    9.213735              0                     0  \n",
      "3    7.768533              0                     1  \n",
      "4   11.141862              0                     0  \n",
      "5    9.106312              1                     0  \n",
      "6   10.007307              0                     0  \n",
      "7    9.077951              0                     0  \n",
      "8   11.127704              0                     1  \n",
      "9   11.141862              1                     1  \n",
      "10   8.149602              0                     0  \n",
      "11   6.857514              0                     0  \n",
      "12   6.921658              0                     0  \n",
      "13   7.649216              0                     0  \n",
      "14   7.961370              0                     0  \n",
      "15   7.901748              0                     0  \n",
      "16   7.592870              0                     1  \n",
      "17   7.714231              0                     1  \n",
      "18   5.308268              0                     0  \n",
      "19   5.726848              0                     0  \n",
      "20   6.853299              0                     0  \n",
      "21   6.835185              0                     0  \n",
      "22  10.502379              0                     0  \n",
      "23   7.998335              0                     1  \n",
      "24   6.587550              0                     1  \n",
      "25   7.977625              0                     0  \n",
      "26   7.149132              0                     0  \n",
      "27   7.639642              0                     0  \n",
      "28   7.782807              0                     0  \n",
      "29   8.044305              0                     0  \n",
      "..        ...            ...                   ...  \n",
      "52   6.727432              0                     1  \n",
      "53  10.854238              1                     1  \n",
      "54  11.141862              0                     0  \n",
      "55   8.049746              0                     1  \n",
      "56   6.811244              0                     0  \n",
      "57   7.856707              0                     0  \n",
      "58   7.753194              0                     0  \n",
      "59   9.364520              0                     0  \n",
      "60   7.848153              0                     0  \n",
      "61   6.915723              1                     0  \n",
      "62   7.413970              0                     0  \n",
      "63  10.644758              1                     0  \n",
      "64   6.148468              0                     0  \n",
      "65   7.796880              0                     0  \n",
      "66   6.956545              0                     0  \n",
      "67   8.810310              0                     0  \n",
      "68   6.629363              0                     0  \n",
      "69   6.648985              0                     0  \n",
      "70   7.700748              0                     0  \n",
      "71   7.751045              1                     0  \n",
      "72   8.998755              0                     0  \n",
      "73   7.658700              0                     0  \n",
      "74   6.502790              0                     0  \n",
      "75   7.677400              0                     0  \n",
      "76   6.113682              0                     0  \n",
      "77   6.396930              1                     0  \n",
      "78   6.436150              0                     0  \n",
      "79   5.872118              0                     0  \n",
      "80   6.906755              0                     0  \n",
      "81   8.104401              0                     0  \n",
      "\n",
      "[82 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "df = handle_case_attributes(csv_path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787.7255\n",
      "862.9851\n",
      "1230.1107\n",
      "819.343\n",
      "1087.2977\n",
      "570.0541\n",
      "701.69336\n",
      "628.97485\n",
      "622.3067\n",
      "749.85925\n",
      "689.5211\n",
      "726.7069\n",
      "936.5994\n",
      "762.5785\n",
      "792.7317\n",
      "674.0147\n",
      "761.66614\n",
      "622.02124\n",
      "533.1105\n",
      "1025.8511\n",
      "602.9141\n",
      "1041.8448\n",
      "730.19824\n",
      "961.4267\n",
      "697.7196\n",
      "813.6659\n",
      "759.49005\n",
      "694.12024\n",
      "882.05237\n",
      "704.60974\n",
      "990.76\n",
      "766.48376\n",
      "904.9805\n",
      "563.57385\n",
      "835.7109\n",
      "824.75195\n",
      "925.1897\n",
      "1072.619\n",
      "723.62\n",
      "703.2485\n",
      "660.7617\n",
      "932.6425\n",
      "1130.1699\n",
      "747.48206\n",
      "1229.5876\n",
      "2107.146\n",
      "799.9073\n",
      "967.8887\n",
      "790.83563\n",
      "1560.2429\n",
      "873.8374\n",
      "550.0825\n",
      "674.3357\n",
      "805.61993\n",
      "891.3391\n",
      "946.3739\n",
      "866.5358\n",
      "1500.0485\n",
      "865.671\n",
      "586.0764\n",
      "670.5509\n",
      "967.54694\n",
      "1025.6387\n",
      "958.6667\n",
      "871.83765\n",
      "601.90594\n",
      "1123.396\n",
      "1284.5771\n",
      "908.7042\n",
      "837.37897\n",
      "632.5162\n",
      "875.73816\n",
      "641.46484\n",
      "638.82\n",
      "1092.3218\n",
      "1411.3582\n",
      "893.15576\n",
      "1423.2323\n",
      "678.9231\n",
      "1135.1378\n",
      "607.6304\n",
      "753.3191\n",
      "877.6154\n",
      "1927.0913\n",
      "681.7512\n",
      "1987.3579\n",
      "681.22076\n",
      "814.8993\n",
      "2078.0332\n",
      "772.9026\n",
      "845.5812\n",
      "641.97205\n",
      "1063.2904\n",
      "924.4271\n",
      "633.0752\n",
      "920.59863\n",
      "808.8901\n",
      "992.6543\n",
      "691.1599\n",
      "710.20795\n",
      "1850.3376\n",
      "1179.6656\n",
      "1106.6594\n",
      "1272.1804\n",
      "852.26514\n",
      "716.5105\n",
      "826.0199\n",
      "692.13824\n",
      "760.1931\n",
      "879.51575\n",
      "852.1545\n",
      "1184.9464\n",
      "1082.1505\n",
      "730.34607\n",
      "980.41003\n",
      "804.3187\n",
      "1033.492\n",
      "1081.0675\n",
      "875.819\n",
      "888.74023\n",
      "868.75964\n",
      "794.02075\n",
      "2050.4756\n",
      "809.43097\n",
      "690.5216\n",
      "1509.2694\n",
      "2037.818\n",
      "880.17224\n",
      "1008.26495\n",
      "1651.3877\n",
      "1355.5114\n",
      "992.2617\n",
      "732.88513\n",
      "699.4376\n",
      "2042.1736\n",
      "918.92126\n",
      "617.7243\n",
      "892.68506\n",
      "865.9287\n",
      "865.3544\n",
      "2052.812\n",
      "1103.8524\n",
      "979.593\n",
      "879.1554\n",
      "889.291\n",
      "1114.3357\n",
      "689.3542\n",
      "1965.24\n",
      "1507.6534\n",
      "792.3111\n",
      "869.52686\n",
      "750.70667\n",
      "889.16895\n",
      "868.797\n",
      "1160.3976\n",
      "707.27466\n",
      "1877.5967\n",
      "1059.2759\n",
      "1467.8829\n",
      "669.6047\n",
      "1589.4496\n",
      "1022.62366\n",
      "877.5716\n",
      "777.1166\n",
      "1283.9811\n",
      "908.8246\n",
      "2213.8003\n",
      "1015.75104\n",
      "1171.0054\n",
      "2120.3657\n",
      "622.27057\n",
      "740.9066\n",
      "1294.1705\n",
      "1139.2727\n",
      "2046.8665\n",
      "1597.1862\n",
      "889.18555\n",
      "1265.1698\n",
      "933.2711\n",
      "1326.3214\n",
      "495.48413\n",
      "2198.6682\n",
      "2277.0898\n",
      "591.1708\n",
      "1440.1215\n",
      "1752.0107\n",
      "1384.9038\n",
      "786.4783\n",
      "1520.6055\n",
      "1030.2642\n",
      "1121.6078\n",
      "771.89514\n",
      "2195.0283\n",
      "1026.5176\n",
      "1530.6572\n",
      "1181.1022\n",
      "1069.5076\n",
      "937.6803\n",
      "1035.931\n",
      "1086.2935\n",
      "1180.8182\n",
      "964.26843\n",
      "760.0613\n",
      "1611.1638\n",
      "1032.192\n",
      "818.2106\n",
      "1681.4962\n",
      "2494.9976\n",
      "772.4995\n",
      "1724.1418\n",
      "1566.7454\n",
      "1159.015\n",
      "1362.7755\n",
      "759.0502\n",
      "1118.4187\n",
      "2512.2957\n",
      "807.80426\n",
      "828.14233\n",
      "830.27234\n",
      "2194.833\n",
      "783.19464\n",
      "1834.7157\n",
      "1052.2703\n",
      "1051.0306\n",
      "986.0764\n",
      "1188.8091\n",
      "443.63855\n",
      "1613.8695\n",
      "2226.4067\n",
      "1559.1543\n",
      "986.0143\n",
      "1023.07495\n",
      "2316.1104\n",
      "1045.6848\n",
      "899.4113\n",
      "1570.9855\n",
      "1581.0298\n",
      "2067.058\n",
      "1838.5342\n",
      "1787.4111\n",
      "590.08923\n",
      "2384.8325\n",
      "1004.1113\n",
      "926.6238\n",
      "901.86523\n",
      "2538.9878\n",
      "832.66125\n",
      "2239.9785\n",
      "687.7506\n",
      "1298.6404\n",
      "1852.403\n",
      "2133.23\n",
      "883.53015\n",
      "1518.6559\n",
      "1263.0575\n",
      "2158.0293\n",
      "1441.183\n",
      "899.38165\n",
      "1484.0592\n",
      "958.53876\n",
      "812.20905\n",
      "568.2636\n",
      "2113.227\n",
      "3077.4585\n",
      "546.6452\n",
      "1720.1385\n",
      "999.8694\n",
      "825.8862\n",
      "638.64624\n",
      "1867.4886\n",
      "1269.1196\n",
      "1208.7853\n",
      "839.8202\n",
      "2640.816\n",
      "928.5694\n",
      "1824.1099\n",
      "1371.0159\n",
      "1105.2659\n",
      "949.82263\n",
      "967.3318\n",
      "815.81384\n",
      "908.7062\n",
      "1285.4816\n",
      "775.2347\n",
      "2260.088\n",
      "968.79565\n",
      "774.68787\n",
      "1393.7319\n",
      "2406.071\n",
      "1505.5648\n",
      "1057.3401\n",
      "910.69867\n",
      "1066.0125\n",
      "1411.5393\n",
      "1766.7783\n",
      "1153.0568\n",
      "2572.4023\n",
      "901.94324\n",
      "1065.4893\n",
      "805.2877\n",
      "2596.5151\n",
      "625.43256\n",
      "2575.6711\n",
      "940.0572\n",
      "858.09845\n",
      "1009.8031\n",
      "1069.7897\n",
      "1208.7433\n",
      "929.7203\n",
      "2432.303\n",
      "1533.7168\n",
      "2320.3962\n",
      "1342.2659\n",
      "2382.2449\n",
      "1151.6238\n",
      "925.4552\n",
      "3007.19\n",
      "1649.5754\n",
      "2221.919\n",
      "2379.9705\n",
      "386.11102\n",
      "970.5564\n",
      "2657.0608\n",
      "1260.6361\n",
      "824.2711\n",
      "1065.447\n",
      "2498.6091\n",
      "1002.08875\n",
      "2311.9294\n",
      "792.755\n",
      "1345.2032\n",
      "2243.3853\n",
      "1579.1255\n",
      "978.68665\n",
      "2113.8955\n",
      "1387.6549\n",
      "2163.149\n",
      "1394.3031\n",
      "979.8167\n",
      "1756.7596\n",
      "849.3873\n",
      "953.2064\n",
      "635.5903\n",
      "2607.7844\n",
      "2585.7168\n",
      "777.4281\n",
      "1446.0496\n",
      "1965.2542\n",
      "1102.3516\n",
      "752.25476\n",
      "1799.322\n",
      "1435.1624\n",
      "1246.6909\n",
      "712.8634\n",
      "3123.2905\n",
      "1377.6365\n",
      "1981.0178\n",
      "1545.0792\n",
      "922.072\n",
      "1179.394\n",
      "1100.2112\n",
      "1032.2498\n",
      "1158.4294\n",
      "1559.0605\n",
      "1191.9332\n",
      "2232.628\n",
      "1207.498\n",
      "778.581\n",
      "1329.7008\n",
      "2228.7605\n",
      "912.2886\n",
      "1069.9302\n",
      "1008.0907\n",
      "1253.0779\n",
      "1003.43555\n",
      "2106.5425\n",
      "839.10706\n",
      "2788.7798\n",
      "827.5239\n",
      "1201.9032\n",
      "838.3916\n",
      "2777.4624\n",
      "860.6299\n",
      "2442.819\n",
      "1048.837\n",
      "1930.8527\n",
      "1033.8059\n",
      "1057.1587\n",
      "1147.9816\n",
      "1033.6216\n",
      "2554.859\n",
      "1456.8768\n",
      "2518.6133\n",
      "2205.275\n",
      "2299.123\n",
      "987.58466\n",
      "760.17017\n",
      "2955.6128\n",
      "2757.8413\n",
      "2612.206\n",
      "2534.2124\n",
      "812.40704\n",
      "1043.8567\n",
      "2476.5315\n",
      "753.61584\n",
      "960.2378\n",
      "1465.5657\n",
      "1667.6332\n",
      "1438.1166\n",
      "2768.166\n",
      "705.551\n",
      "756.3722\n",
      "2681.0552\n",
      "1736.8328\n",
      "619.79736\n",
      "1785.6482\n",
      "1518.8674\n",
      "2657.6543\n",
      "1699.1245\n",
      "939.265\n",
      "642.22565\n",
      "1331.6421\n",
      "829.526\n",
      "1873.4207\n",
      "2368.5178\n",
      "2886.5186\n",
      "1578.419\n",
      "1313.6395\n",
      "863.434\n",
      "1044.3414\n",
      "590.08685\n",
      "1359.9867\n",
      "1083.663\n",
      "1686.8528\n",
      "759.8593\n",
      "2729.8079\n",
      "785.6194\n",
      "2261.3955\n",
      "1467.8174\n",
      "946.3623\n",
      "825.1542\n",
      "743.343\n",
      "664.18286\n",
      "900.95215\n",
      "1307.2383\n",
      "1621.0712\n",
      "2531.6042\n",
      "1314.2096\n",
      "819.6476\n",
      "2134.0986\n",
      "2716.1648\n",
      "1340.8112\n",
      "742.6781\n",
      "761.5083\n",
      "1533.773\n",
      "942.2953\n",
      "2196.5444\n",
      "1108.2319\n",
      "2951.5483\n",
      "661.8748\n",
      "1077.9045\n",
      "811.6588\n",
      "2432.453\n",
      "1090.4375\n",
      "2224.0017\n",
      "818.2847\n",
      "1503.4352\n",
      "1013.0776\n",
      "1072.6038\n",
      "481.00934\n",
      "1031.2206\n",
      "1408.7869\n",
      "2809.1394\n",
      "2950.7927\n",
      "2426.2144\n",
      "1253.7504\n",
      "1279.7548\n",
      "589.0559\n",
      "2405.7217\n",
      "2559.575\n",
      "2400.9712\n",
      "2861.7344\n",
      "649.64185\n",
      "1047.9757\n",
      "2602.846\n",
      "1119.2603\n",
      "791.20807\n",
      "1506.19\n",
      "2893.7334\n",
      "1281.2408\n",
      "1847.2761\n",
      "650.16724\n",
      "1651.5001\n",
      "2206.81\n",
      "1457.6891\n",
      "696.042\n",
      "1496.5177\n",
      "1300.4685\n",
      "2926.3118\n",
      "1759.612\n",
      "1075.8025\n",
      "1589.98\n",
      "1159.2373\n",
      "992.49524\n",
      "1633.2179\n",
      "2397.858\n",
      "1900.2063\n",
      "622.2716\n",
      "1155.5859\n",
      "1779.7605\n",
      "905.16583\n",
      "605.2887\n",
      "1712.0884\n",
      "552.8842\n",
      "1940.5559\n",
      "758.8545\n",
      "2457.561\n",
      "897.92957\n",
      "1321.6705\n",
      "1240.9318\n",
      "952.9429\n",
      "1272.8314\n",
      "882.4702\n",
      "1422.4055\n",
      "968.08765\n",
      "1247.3873\n",
      "1413.7849\n",
      "2404.9426\n",
      "1172.2495\n",
      "732.6222\n",
      "1805.3269\n",
      "2189.3796\n",
      "754.27\n",
      "793.89575\n",
      "801.4591\n",
      "1128.6346\n",
      "1147.1285\n",
      "2469.4922\n",
      "771.4043\n",
      "2369.3364\n",
      "1079.5721\n",
      "744.6873\n",
      "1164.529\n",
      "2282.191\n",
      "599.80566\n",
      "2685.4348\n",
      "574.66614\n",
      "1576.5366\n",
      "683.9569\n",
      "1188.1182\n",
      "1653.7\n",
      "1071.9326\n",
      "2522.7732\n",
      "2357.4844\n",
      "1954.022\n",
      "2008.4329\n",
      "1763.9629\n",
      "1221.1428\n",
      "1334.9578\n",
      "2063.205\n",
      "2622.122\n",
      "2518.8567\n",
      "2570.5667\n",
      "349.139\n",
      "900.91614\n",
      "2535.599\n",
      "834.43243\n",
      "680.0698\n",
      "1492.0718\n",
      "1352.1414\n",
      "1291.4332\n",
      "1672.1052\n",
      "632.0484\n",
      "1226.4382\n",
      "1911.3711\n",
      "1181.4021\n",
      "534.5979\n",
      "1284.9355\n",
      "1273.408\n",
      "2656.7222\n",
      "1879.3981\n",
      "805.1285\n",
      "1255.6418\n",
      "1276.025\n",
      "1260.3401\n",
      "2115.296\n",
      "1800.9635\n",
      "866.57446\n",
      "559.0343\n",
      "1073.6091\n",
      "1853.1884\n",
      "767.4635\n",
      "519.24805\n",
      "1270.0878\n",
      "876.4115\n",
      "1697.0529\n",
      "635.5486\n",
      "2496.8667\n",
      "872.2733\n",
      "1515.8623\n",
      "762.9567\n",
      "836.2286\n",
      "1356.9131\n",
      "705.57086\n",
      "969.98315\n",
      "934.38666\n",
      "1067.8712\n",
      "1415.1152\n",
      "2369.5432\n",
      "1202.4214\n",
      "749.58264\n",
      "1607.1082\n",
      "1319.701\n",
      "725.90704\n",
      "800.5904\n",
      "641.29816\n",
      "1183.0181\n",
      "1078.1117\n",
      "1589.8237\n",
      "918.6579\n",
      "2509.7095\n",
      "1025.394\n",
      "691.34625\n",
      "1349.8035\n",
      "2183.2976\n",
      "1542.669\n",
      "2311.725\n",
      "687.4578\n",
      "1363.3486\n",
      "1593.6099\n",
      "1045.8647\n",
      "1571.8989\n",
      "1121.328\n",
      "2583.023\n",
      "2833.7012\n",
      "2558.7568\n",
      "1559.1018\n",
      "1360.2628\n",
      "1121.0042\n",
      "1002.89703\n",
      "2164.209\n",
      "2366.0322\n",
      "2157.3916\n",
      "1139.8434\n",
      "1587.2819\n",
      "878.18524\n",
      "2225.7249\n",
      "968.3744\n",
      "1080.6555\n",
      "1344.6714\n",
      "1894.0449\n",
      "1032.1765\n",
      "1423.2898\n",
      "839.65265\n",
      "1072.0077\n",
      "2149.4768\n",
      "1528.9606\n",
      "1205.5957\n",
      "1154.0842\n",
      "902.01404\n",
      "2157.8862\n",
      "1413.511\n",
      "688.43665\n",
      "1470.8208\n",
      "1315.5367\n",
      "1105.0491\n",
      "1612.734\n",
      "2223.781\n",
      "1797.9419\n",
      "1121.1302\n",
      "1109.2871\n",
      "1575.9453\n",
      "720.4595\n",
      "477.99435\n",
      "1041.6986\n",
      "1022.44824\n",
      "1762.8672\n",
      "595.495\n",
      "2390.3765\n",
      "672.6812\n",
      "1107.2861\n",
      "954.3819\n",
      "872.5155\n",
      "1208.5087\n",
      "633.3919\n",
      "901.3841\n",
      "700.8912\n",
      "1086.8179\n",
      "1415.1152\n",
      "1901.9863\n",
      "951.1384\n",
      "698.0213\n",
      "1470.1371\n",
      "1730.3563\n",
      "549.0813\n",
      "1170.3779\n",
      "1291.4072\n",
      "1026.9767\n",
      "577.7074\n",
      "1891.581\n",
      "864.64886\n",
      "2105.2168\n",
      "1333.0884\n",
      "1230.6885\n",
      "1296.513\n",
      "2143.5603\n",
      "1051.4824\n",
      "2308.167\n",
      "1074.4369\n",
      "712.67615\n",
      "1039.488\n",
      "675.61847\n",
      "1423.8905\n",
      "1121.328\n",
      "2248.0781\n",
      "2063.106\n",
      "2514.1074\n",
      "1514.89\n",
      "1377.0137\n",
      "850.4106\n",
      "1036.4692\n",
      "2159.227\n",
      "1968.9705\n",
      "1791.1337\n",
      "1823.3546\n",
      "1544.3909\n",
      "878.18524\n",
      "1904.9663\n",
      "750.7049\n",
      "883.36597\n",
      "1196.4108\n",
      "2229.7417\n",
      "496.89777\n",
      "1709.9001\n",
      "617.5722\n",
      "1175.4624\n",
      "1940.644\n",
      "1525.9346\n",
      "915.6948\n",
      "1232.8206\n",
      "1139.9293\n",
      "1175.4451\n",
      "1694.0139\n",
      "665.27625\n",
      "1654.0522\n",
      "1484.565\n",
      "1014.2569\n",
      "1520.432\n",
      "2144.3997\n",
      "805.4875\n",
      "1311.6719\n",
      "1109.2871\n",
      "2144.5886\n",
      "769.8644\n",
      "481.30457\n",
      "1278.6179\n",
      "1031.4866\n",
      "1478.3628\n",
      "1028.9385\n",
      "1361.4802\n",
      "657.8932\n",
      "1260.8807\n",
      "1193.8488\n",
      "708.56006\n",
      "1192.4578\n",
      "995.401\n",
      "1171.7357\n",
      "686.8959\n",
      "1086.8179\n",
      "1173.6554\n",
      "1919.1052\n",
      "1002.7836\n",
      "740.18335\n",
      "1671.444\n",
      "2296.9512\n",
      "705.6633\n",
      "1101.1897\n",
      "1541.4692\n",
      "1066.5085\n",
      "703.8609\n",
      "1731.394\n",
      "868.51666\n",
      "2087.961\n",
      "844.4683\n",
      "691.34625\n",
      "1219.9336\n",
      "2117.9766\n",
      "1205.1279\n",
      "2237.3894\n",
      "1274.4836\n",
      "685.86017\n",
      "1031.481\n",
      "1102.1604\n",
      "1281.6287\n",
      "1002.4703\n",
      "2332.9314\n",
      "2142.2932\n",
      "2474.4133\n",
      "1602.8988\n",
      "1401.2942\n",
      "819.8644\n",
      "974.013\n",
      "1772.236\n",
      "2088.562\n",
      "1458.7257\n",
      "1992.9072\n",
      "1488.8376\n",
      "1016.993\n",
      "2061.3965\n",
      "819.76776\n",
      "580.50055\n",
      "795.27454\n",
      "1905.2806\n",
      "528.73486\n",
      "1662.46\n",
      "487.6833\n",
      "595.0785\n",
      "1536.4938\n",
      "1392.989\n",
      "1017.7052\n",
      "803.16846\n",
      "1122.4937\n",
      "1895.6332\n",
      "1051.4078\n",
      "629.14746\n",
      "1408.5813\n",
      "1023.3807\n",
      "847.5576\n",
      "1459.9769\n",
      "1475.1329\n",
      "743.743\n",
      "1015.5519\n",
      "818.2086\n",
      "861.7174\n",
      "681.46826\n",
      "755.3686\n",
      "988.0427\n",
      "957.8356\n",
      "1349.3295\n",
      "963.317\n",
      "2078.7786\n",
      "772.743\n",
      "1180.54\n",
      "983.69165\n",
      "615.3795\n",
      "1164.7052\n",
      "1304.4923\n",
      "885.41956\n",
      "868.3728\n",
      "698.4732\n",
      "558.5842\n",
      "1546.8225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883.3683\n",
      "572.1315\n",
      "1359.6616\n",
      "1039.9907\n",
      "896.8491\n",
      "977.18164\n",
      "873.91254\n",
      "902.69543\n",
      "669.5906\n",
      "1346.3961\n",
      "883.53955\n",
      "1326.9358\n",
      "597.7136\n",
      "1346.0071\n",
      "939.7698\n",
      "1872.07\n",
      "910.1621\n",
      "1594.5007\n",
      "944.0077\n",
      "1042.7206\n",
      "969.2949\n",
      "545.94617\n",
      "1364.4487\n",
      "639.5012\n",
      "1935.0905\n",
      "1895.5659\n",
      "1769.1494\n",
      "1358.337\n",
      "1263.4343\n",
      "786.1299\n",
      "430.17963\n",
      "1671.8572\n",
      "1443.4523\n",
      "2085.915\n",
      "1866.4015\n",
      "1311.2599\n",
      "823.1432\n",
      "1963.8677\n",
      "735.36206\n",
      "591.6456\n",
      "773.0463\n",
      "1805.7332\n",
      "759.0293\n",
      "1367.0554\n",
      "741.80725\n",
      "700.62036\n",
      "1307.436\n",
      "1228.1028\n",
      "1168.5742\n",
      "866.0546\n",
      "1084.5684\n",
      "1852.877\n",
      "1284.6687\n",
      "595.3761\n",
      "1029.8928\n",
      "986.17944\n",
      "771.40375\n",
      "1366.667\n",
      "1715.2429\n",
      "1594.1831\n",
      "1073.4314\n",
      "780.1279\n",
      "1147.3044\n",
      "830.4275\n",
      "899.10504\n",
      "586.2684\n",
      "878.47943\n",
      "1506.0798\n",
      "705.9091\n",
      "1192.6964\n",
      "939.66345\n",
      "1038.5995\n",
      "907.22473\n",
      "613.0437\n",
      "939.03516\n",
      "1196.3679\n",
      "744.6745\n",
      "759.32434\n",
      "778.4402\n",
      "963.357\n",
      "1622.9814\n",
      "870.84607\n",
      "847.42737\n",
      "1369.8649\n",
      "1060.2388\n",
      "1070.5895\n",
      "831.052\n",
      "1340.8604\n",
      "1059.0492\n",
      "664.06946\n",
      "1189.9009\n",
      "862.2306\n",
      "966.0852\n",
      "671.9799\n",
      "987.7091\n",
      "816.54456\n",
      "1825.3549\n",
      "1088.623\n",
      "1960.2917\n",
      "852.7606\n",
      "717.2686\n",
      "925.1191\n",
      "740.37384\n",
      "1333.8103\n",
      "761.69824\n",
      "2284.2317\n",
      "1812.8633\n",
      "1614.4878\n",
      "1303.0364\n",
      "1311.3788\n",
      "775.13275\n",
      "670.2558\n",
      "1675.2053\n",
      "1672.7369\n",
      "1752.2544\n",
      "1715.2407\n",
      "1329.3552\n",
      "763.4109\n",
      "1823.683\n",
      "768.61694\n",
      "782.3177\n",
      "1113.9337\n",
      "1919.8083\n",
      "913.2544\n",
      "1623.8666\n",
      "644.9771\n",
      "543.4823\n",
      "1457.2144\n",
      "1622.057\n",
      "1432.5276\n",
      "954.68756\n",
      "1256.2129\n",
      "1496.5758\n",
      "1247.2166\n",
      "621.7079\n",
      "1039.3597\n",
      "1053.8691\n",
      "787.6891\n",
      "1737.812\n",
      "1779.7554\n",
      "1531.0033\n",
      "1011.00934\n",
      "1063.3785\n",
      "1219.668\n",
      "997.1344\n",
      "887.39355\n",
      "598.36786\n",
      "1069.2981\n",
      "1313.373\n",
      "734.6869\n",
      "2028.9286\n",
      "964.1664\n",
      "1290.9673\n",
      "965.171\n",
      "819.6943\n",
      "859.42847\n",
      "1222.3184\n",
      "890.43695\n",
      "994.3443\n",
      "967.5548\n",
      "961.4343\n",
      "1534.6017\n",
      "1048.6183\n",
      "1039.9375\n",
      "1595.5779\n",
      "870.53186\n",
      "1112.2104\n",
      "1160.0839\n",
      "1154.2864\n",
      "1001.3148\n",
      "868.5895\n",
      "1496.184\n",
      "1190.7886\n",
      "1387.9281\n",
      "807.399\n",
      "893.84467\n",
      "960.8274\n",
      "1700.699\n",
      "1354.0734\n",
      "1603.1798\n",
      "820.18396\n",
      "828.31805\n",
      "941.40027\n",
      "860.9747\n",
      "1391.7787\n",
      "728.66626\n",
      "2067.233\n",
      "1803.2683\n",
      "1928.9324\n",
      "865.6726\n",
      "1556.2134\n",
      "962.8622\n",
      "921.67035\n",
      "2027.9468\n",
      "1665.9492\n",
      "2173.3062\n",
      "1621.1614\n",
      "1832.3525\n",
      "1060.5979\n",
      "1857.6304\n",
      "725.7602\n",
      "935.8526\n",
      "1086.8574\n",
      "2038.1787\n",
      "690.6867\n",
      "1703.592\n",
      "739.756\n",
      "865.2556\n",
      "1469.7185\n",
      "1603.5516\n",
      "1046.8379\n",
      "1074.3462\n",
      "1258.04\n",
      "1815.7375\n",
      "1169.1345\n",
      "1046.4873\n",
      "1160.1359\n",
      "1316.47\n",
      "593.2605\n",
      "1792.7527\n",
      "1762.0139\n",
      "1611.2363\n",
      "1121.4305\n",
      "925.01666\n",
      "1317.7332\n",
      "1128.1779\n",
      "1024.5385\n",
      "916.5451\n",
      "1075.5916\n",
      "1326.8945\n",
      "1040.2747\n",
      "2101.5671\n",
      "815.8082\n",
      "1433.5311\n",
      "1312.0841\n",
      "894.3905\n",
      "1396.7808\n",
      "1355.5796\n",
      "905.583\n",
      "996.13214\n",
      "910.76086\n",
      "993.49475\n",
      "1746.9458\n",
      "1223.7517\n",
      "1047.1515\n",
      "1609.6255\n",
      "1486.6873\n",
      "930.1236\n",
      "1306.7285\n",
      "1298.8583\n",
      "1123.3678\n",
      "711.5474\n",
      "1680.1217\n",
      "1266.0916\n",
      "1539.5438\n",
      "664.7715\n",
      "1322.0756\n",
      "1038.6674\n",
      "1871.3339\n",
      "1042.693\n",
      "1725.6168\n",
      "999.09875\n",
      "1262.2216\n",
      "977.4507\n",
      "1192.3823\n",
      "1720.2659\n",
      "1161.3556\n",
      "2020.4832\n",
      "2019.3823\n",
      "1887.1919\n",
      "1918.738\n",
      "1745.887\n",
      "1154.7527\n",
      "1071.1797\n",
      "1714.3994\n",
      "1965.2714\n",
      "389.6265\n",
      "1736.7358\n",
      "1543.6708\n",
      "1058.7058\n",
      "2399.5195\n",
      "960.6832\n",
      "    id  group  sex  age    score2  smallbin        bmi  time_onset  ane_diam  \\\n",
      "0    1      1    0   71 -0.657735         1  22.656250         7.0     5.000   \n",
      "1    1      0    0   69 -0.260601         1  27.548209        48.0     5.640   \n",
      "2    2      1    1   33 -2.010208         0  25.380000        12.0     4.700   \n",
      "3    2      0    1   28 -1.937681         0  29.069767        10.0     0.000   \n",
      "4    3      0    1   50 -0.880417         0  23.875115       168.0     0.000   \n",
      "5    3      1    1   49 -0.817507         1  27.379665        24.0     5.100   \n",
      "6    4      0    1   47 -1.704438         0  40.000000         5.0     0.000   \n",
      "7    4      1    1   53 -1.705023         1  19.390582        24.0     4.000   \n",
      "8    5      1    1   50 -0.012975         0  31.141869        24.0     4.980   \n",
      "9    5      0    1   50 -0.025385         0  26.423570         8.0     5.600   \n",
      "10   6      0    1   46 -1.950741         0  29.410759         4.0     4.400   \n",
      "11   6      1    1   50 -1.963092         0  24.221453        24.0     4.500   \n",
      "12   7      0    1   53 -1.819756         0  21.604938       120.0     6.000   \n",
      "13   7      1    1   49 -1.860024         0  24.910767        20.0     4.210   \n",
      "14   8      1    1   50 -1.740890         0  27.681661        24.0     6.640   \n",
      "15   8      0    1   48 -1.806499         0  27.681661        24.0     0.000   \n",
      "16   9      0    0   61 -0.816806         1  28.934069        48.0     0.000   \n",
      "17   9      1    0   58 -0.670273         1  24.034610         8.0     4.700   \n",
      "18  10      1    1   63 -2.164651         0  23.836735         4.0     4.630   \n",
      "19  10      0    1   58 -2.213810         0  27.755102         4.0     4.400   \n",
      "20  11      0    1   43 -2.173324         1  28.734694        24.0     0.000   \n",
      "21  11      1    1   41 -2.191658         0  20.987654        24.0     4.300   \n",
      "22  12      0    1   59 -1.230815         1  24.221453         8.0     4.600   \n",
      "23  12      1    1   62 -0.559796         1  28.400548        10.0     4.100   \n",
      "24  13      0    0   62 -1.383597         1  27.239224        96.0     0.000   \n",
      "25  13      1    0   65 -1.221590         1  25.390625        18.0     3.900   \n",
      "26  14      0    1   54 -1.901623         0  21.718066        18.0     6.000   \n",
      "27  14      1    1   47 -1.906157         0  25.351541        24.0     5.336   \n",
      "28  15      0    1   59 -1.591389         0  21.971336        24.0     5.600   \n",
      "29  15      1    1   57 -1.598571         0  24.337480        96.0     4.400   \n",
      "..  ..    ...  ...  ...       ...       ...        ...         ...       ...   \n",
      "52  27      0    1   52 -1.140367         1  22.204082        96.0     4.950   \n",
      "53  27      1    1   51  0.563989         1  26.122449        24.0     4.300   \n",
      "54  28      0    1   41 -1.097852         0  26.729928        24.0     4.000   \n",
      "55  28      1    1   39 -1.121745         1  27.777778         5.0     4.360   \n",
      "56  29      0    0   57 -2.288408         1  29.903029        96.0     4.540   \n",
      "57  29      1    0   63 -1.815946         1  27.055151        13.0     4.250   \n",
      "58  30      0    1   53 -1.641087         0  30.421850       120.0     4.100   \n",
      "59  30      1    1   52 -1.648182         0  23.938990        11.0     4.500   \n",
      "60  31      1    1   52 -1.589733         0  26.729928        12.0     0.000   \n",
      "61  31      0    1   48 -1.434553         0  31.095278        24.0     5.130   \n",
      "62  32      0    1   43 -0.956578         0  29.983588        14.0     0.000   \n",
      "63  32      1    1   37 -0.707165         0  24.618104        24.0     0.000   \n",
      "64  33      0    0   53 -2.106903         1  22.038567        72.0     5.480   \n",
      "65  33      1    0   50 -1.852128         0  22.862369        15.0     4.700   \n",
      "66  34      0    1   68 -1.610389         1  29.384757       120.0     4.190   \n",
      "67  34      1    1   68 -0.867844         0  22.204082        48.0     5.200   \n",
      "68  35      1    1   55 -2.344058         0  20.619254        72.0     0.000   \n",
      "69  35      0    1   59 -2.271741         0  27.732300        48.0     5.050   \n",
      "70  36      1    1   50 -1.698870         1  28.400548        24.0     0.000   \n",
      "71  36      0    1   52 -1.257730         1  28.731747       240.0     4.000   \n",
      "72  37      1    1   54 -1.707943         1  26.573129        24.0     4.400   \n",
      "73  37      0    1   51 -1.747033         0  26.122449        24.0     5.000   \n",
      "74  38      1    1   43 -2.120811         0  29.410000         8.0     6.400   \n",
      "75  38      0    1   41 -1.951066         0  31.887755        18.0     3.910   \n",
      "76  39      0    1   57 -2.013845         0  27.005131       168.0     4.700   \n",
      "77  39      1    1   58 -1.378944         1  24.221453        48.0     4.800   \n",
      "78  40      1    0   55 -2.391192         1  20.253848        24.0     0.000   \n",
      "79  40      0    0   49 -2.286890         1  27.335640        24.0     6.810   \n",
      "80  41      1    0   58 -1.940001         1  27.053803        12.0     0.000   \n",
      "81  41      0    0   64 -1.384039         1  27.343750        48.0     4.400   \n",
      "\n",
      "    diabetes  ...            5            6            7            8  \\\n",
      "0          1  ...  1102.351562  1044.341431   905.165833   767.463501   \n",
      "1          1  ...   752.254761   590.086853   605.288696   519.248047   \n",
      "2          0  ...  2788.779785  2951.548340  2369.336426  2509.709473   \n",
      "3          0  ...   839.107056  1108.231934   771.404297   918.657898   \n",
      "4          0  ...  1008.090698   761.508301   801.459106   641.298157   \n",
      "5          0  ...  1253.077881  1533.772949  1128.634644  1183.018066   \n",
      "6          0  ...  1329.700806  2134.098633  1805.326904  1607.108154   \n",
      "7          0  ...  2228.760498  2716.164795  2189.379639  1319.701050   \n",
      "8          0  ...  2777.462402  2432.452881  2282.190918  2183.297607   \n",
      "9          0  ...   838.391602   811.658813  1164.529053  1349.803467   \n",
      "10         0  ...   635.590271  1873.420654  1633.217896  2115.295898   \n",
      "11         0  ...  2607.784424  2368.517822  2397.857910  1800.963501   \n",
      "12         0  ...  2163.148926  2657.654297  2926.311768  2656.722168   \n",
      "13         0  ...  1394.303101  1699.124512  1759.612061  1879.398071   \n",
      "14         0  ...  1981.017822  2261.395508  1321.670532  1515.862305   \n",
      "15         0  ...  1545.079224  1467.817383  1240.931763   762.956726   \n",
      "16         1  ...   978.686646   619.797363   696.041992   534.597900   \n",
      "17         0  ...  1579.125488  1736.832764  1457.689087  1181.402100   \n",
      "18         0  ...  1799.322021  1359.986694  1712.088379  1270.087769   \n",
      "19         0  ...  1435.162354  1083.662964   552.884216   876.411499   \n",
      "20         0  ...  1387.654907  1518.867432  1300.468506  1273.407959   \n",
      "21         0  ...  2113.895508  1785.648193  1496.517700  1284.935547   \n",
      "22         0  ...  2106.542480  2196.544434  2469.492188  1589.823730   \n",
      "23         0  ...  1003.435547   942.295288  1147.128540  1078.111694   \n",
      "24         0  ...  1201.903198  1077.904541   744.687317   691.346252   \n",
      "25         0  ...   827.523926   661.874817  1079.572144  1025.394043   \n",
      "26         0  ...  2442.819092  2224.001709  2685.434814  2311.725098   \n",
      "27         0  ...   860.629883  1090.437500   599.805664  1542.668945   \n",
      "28         0  ...  1069.930176   742.678101   793.895752   800.590393   \n",
      "29         0  ...   912.288574  1340.811157   754.270020   725.907043   \n",
      "..       ...  ...          ...          ...          ...          ...   \n",
      "52         0  ...  1345.203247   756.372192  1651.500122  1226.438232   \n",
      "53         0  ...  2243.385254  2681.055176  2206.810059  1911.371094   \n",
      "54         0  ...  2585.716797  2886.518555  1900.206299   866.574463   \n",
      "55         0  ...   777.428101  1578.418945   622.271606   559.034302   \n",
      "56         0  ...  1756.759644   642.225647  1589.979980  1255.641846   \n",
      "57         0  ...   979.816711   939.265015  1075.802490   805.128479   \n",
      "58         0  ...  1559.060547  1307.238281  1247.387329  1067.871216   \n",
      "59         0  ...  1158.429443   900.952148   968.087646   934.386658   \n",
      "60         0  ...  1032.249756   664.182861  1422.405518   969.983154   \n",
      "61         0  ...  1100.211182   743.343018   882.470215   705.570862   \n",
      "62         0  ...  1065.447021  1465.565674  1506.189941  1492.071777   \n",
      "63         0  ...   824.271118   960.237793   791.208069   680.069824   \n",
      "64         0  ...  2518.613281  2950.792725  1954.021973  2558.756836   \n",
      "65         0  ...  1456.876831  2809.139404  2357.484375  2833.701172   \n",
      "66         0  ...  2554.858887  1408.786865  2522.773193  2583.022949   \n",
      "67         0  ...  1033.621582  1031.220581  1071.932617  1121.328003   \n",
      "68         0  ...  1057.158691  1072.603760  1188.118164  1045.864746   \n",
      "69         0  ...  1147.981567   481.009338  1653.699951  1571.898926   \n",
      "70         0  ...   987.584656  1279.754761  1221.142822  1121.004150   \n",
      "71         0  ...   760.170166   589.055908  1334.957764  1002.897034   \n",
      "72         0  ...  2955.612793  2405.721680  2063.205078  2164.208984   \n",
      "73         0  ...  2757.841309  2559.574951  2622.122070  2366.032227   \n",
      "74         0  ...  2299.123047  1253.750366  1763.962891  1360.262817   \n",
      "75         0  ...  2205.274902  2426.214355  2008.432861  1559.101807   \n",
      "76         0  ...  2612.206055  2400.971191  2518.856689  2157.391602   \n",
      "77         0  ...  2534.212402  2861.734375  2570.566650  1139.843384   \n",
      "78         0  ...   753.615845  1119.260254   834.432434   968.374390   \n",
      "79         0  ...  2476.531494  2602.845947  2535.599121  2225.724854   \n",
      "80         0  ...  1043.856689  1047.975708   900.916138   878.185242   \n",
      "81         1  ...   812.407043   649.641846   349.139008  1587.281860   \n",
      "\n",
      "              9           10           11           12           13  \\\n",
      "0    720.459473   769.864380   681.468262   830.427490   997.134399   \n",
      "1    477.994354   481.304565   755.368591   899.105042   887.393555   \n",
      "2   2105.216797  2087.960938  1326.935791   966.085205  1387.928101   \n",
      "3    864.648865   868.516663   883.539551   862.230591  1190.788574   \n",
      "4   1291.407227  1541.469238   873.912537  1340.860352  1154.286377   \n",
      "5   1026.976685  1066.508545   902.695435  1059.049194  1001.314819   \n",
      "6   1470.137085  1671.443970  1359.661621  1369.864868  1595.577881   \n",
      "7   1730.356323  2296.951172  1039.990723  1060.238770   870.531860   \n",
      "8   2143.560303  2117.976562  1872.069946  1825.354858  1700.698975   \n",
      "9   1296.512939  1219.933594   939.769775   816.544556   960.827393   \n",
      "10  1612.734009  1520.432007  1459.976929  1366.666992  1737.812012   \n",
      "11  2223.781006  2144.399658  1475.132935  1715.242920  1779.755371   \n",
      "12  2157.886230  1175.445068  1895.633179  1852.876953  1496.575806   \n",
      "13  1413.510986  1694.013916  1051.407837  1284.668701  1247.216553   \n",
      "14  1107.286133  1260.880737  1180.540039  1038.599487  1290.967285   \n",
      "15   954.381897  1193.848755   983.691650   907.224731   965.171021   \n",
      "16  1205.595703   915.694824  1017.705200  1168.574219  1432.527588   \n",
      "17  1528.960571  1525.934570  1392.989014  1228.102783  1622.057007   \n",
      "18  1041.698608  1278.617920   988.042725   586.268372   598.367859   \n",
      "19  1022.448242  1031.486572   957.835571   878.479431  1069.298096   \n",
      "20   902.014038  1139.929321  1122.493652  1084.568359  1256.212891   \n",
      "21  1154.084229  1232.820557   803.168457   866.054626   954.687561   \n",
      "22  1891.581055  1731.394043  1346.396118  1189.900879  1496.183960   \n",
      "23   577.707397   703.860901   669.590576   664.069458   868.589478   \n",
      "24  1230.688477   691.346252  1346.007080   987.709106   893.844666   \n",
      "25  1333.088379   844.468323   597.713623   671.979919   807.398987   \n",
      "26  2308.166992  2237.389404  1594.500732  1960.291748  1603.179810   \n",
      "27  1051.482422  1205.127930   910.162109  1088.623047  1354.073364   \n",
      "28  1170.377930  1101.189697   977.181641   831.052002  1160.083862   \n",
      "29   549.081299   705.663330   896.849121  1070.589478  1112.210449   \n",
      "..          ...          ...          ...          ...          ...   \n",
      "52  1072.007690  1175.462402   595.078491   700.620361   543.482300   \n",
      "53  2149.476807  1940.644043  1536.493774  1307.436035  1457.214355   \n",
      "54  1797.941895   805.487488   743.742981  1594.183105  1531.003296   \n",
      "55  1121.130249  1311.671875  1015.551880  1073.431396  1011.009338   \n",
      "56  1470.820801  1654.052246  1408.581299  1029.892822  1039.359741   \n",
      "57   688.436646   665.276245   629.147461   595.376099   621.707886   \n",
      "58  1086.817871  1086.817871   698.473206   778.440186   967.554810   \n",
      "59   700.891174   686.895874   868.372803   759.324341   994.344299   \n",
      "60   901.384094  1171.735718   885.419556   744.674500   890.436951   \n",
      "61   633.391907   995.401001  1304.492310  1196.367920  1222.318359   \n",
      "62  1344.671387  1196.410767   795.274536   773.046326  1113.933716   \n",
      "63  1080.655518   883.365967   580.500549   591.645630   782.317688   \n",
      "64  2514.107422  2474.413330  1769.149414  1614.487793  1928.932373   \n",
      "65  2063.105957  2142.293213  1895.565918  1812.863281  1803.268311   \n",
      "66  2248.078125  2332.931396  1935.090454  2284.231689  2067.232910   \n",
      "67  1121.328003  1002.470276   639.501221   761.698242   728.666260   \n",
      "68   675.618469  1102.160400   545.946167   740.373840   860.974670   \n",
      "69  1423.890503  1281.628662  1364.448730  1333.810303  1391.778687   \n",
      "70   850.410583   819.864380   786.129883   775.132751   962.862183   \n",
      "71  1036.469238   974.013000   430.179626   670.255798   921.670349   \n",
      "72  2159.227051  1772.235962  1671.857178  1675.205322  2027.946777   \n",
      "73  1968.970459  2088.562012  1443.452271  1672.736938  1665.949219   \n",
      "74  1377.013672  1401.294189  1263.434326  1311.378784  1556.213379   \n",
      "75  1514.890015  1602.898804  1358.337036  1303.036377   865.672607   \n",
      "76  1791.133667  1458.725708  2085.915039  1752.254395  2173.306152   \n",
      "77  1823.354614  1992.907227  1866.401489  1715.240723  1621.161377   \n",
      "78   750.704895   819.767761   735.362061   768.616943   725.760193   \n",
      "79  1904.966309  2061.396484  1963.867676  1823.682983  1857.630371   \n",
      "80   878.185242  1016.992981   823.143188   763.410889  1060.597900   \n",
      "81  1544.390869  1488.837646  1311.259888  1329.355225  1832.352539   \n",
      "\n",
      "             14  \n",
      "0   1128.177856  \n",
      "1   1024.538452  \n",
      "2   1539.543823  \n",
      "3   1266.091553  \n",
      "4   1298.858276  \n",
      "5   1123.367798  \n",
      "6   1609.625488  \n",
      "7   1486.687256  \n",
      "8   1871.333862  \n",
      "9   1038.667358  \n",
      "10  1792.752686  \n",
      "11  1762.013916  \n",
      "12  1815.737549  \n",
      "13  1169.134521  \n",
      "14  1433.531128  \n",
      "15  1312.084106  \n",
      "16  1046.837891  \n",
      "17  1603.551636  \n",
      "18   916.545105  \n",
      "19  1075.591553  \n",
      "20  1258.040039  \n",
      "21  1074.346191  \n",
      "22  1680.121704  \n",
      "23   711.547424  \n",
      "24  1322.075562  \n",
      "25   664.771484  \n",
      "26  1725.616821  \n",
      "27  1042.692993  \n",
      "28  1306.728516  \n",
      "29   930.123596  \n",
      "..          ...  \n",
      "52   865.255615  \n",
      "53  1469.718506  \n",
      "54  1611.236328  \n",
      "55  1121.430542  \n",
      "56  1160.135864  \n",
      "57  1046.487305  \n",
      "58   910.760864  \n",
      "59   996.132141  \n",
      "60   905.583008  \n",
      "61  1355.579590  \n",
      "62  1086.857422  \n",
      "63   935.852600  \n",
      "64  1887.191895  \n",
      "65  2019.382324  \n",
      "66  2020.483154  \n",
      "67  1161.355591  \n",
      "68  1192.382324  \n",
      "69  1720.265869  \n",
      "70  1154.752686  \n",
      "71  1071.179688  \n",
      "72  1714.399414  \n",
      "73  1965.271362  \n",
      "74  1745.886963  \n",
      "75  1918.738037  \n",
      "76   389.626495  \n",
      "77  1736.735840  \n",
      "78   960.683228  \n",
      "79  2399.519531  \n",
      "80  1058.705811  \n",
      "81  1543.670776  \n",
      "\n",
      "[82 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "pre_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', \n",
    "                                        input_shape=(Config.IMAGE_DIM,Config.IMAGE_DIM,3))\n",
    "x = pre_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "model = tf.keras.Model(inputs=pre_model.input, outputs=x)\n",
    "for i in range(14):\n",
    "    IMG_ID = i+1\n",
    "    df[str(IMG_ID)]=0\n",
    "    for j in dataset_train.case_id:\n",
    "        img = dataset_train.load_case_image(j,IMG_ID)[0]\n",
    "        #print(img.shape)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        features = model.predict(img)\n",
    "        \n",
    "        features = np.squeeze(features)\n",
    "        #f = np.mean(features)\n",
    "        f = np.dot(features,features.T)\n",
    "        print(f)\n",
    "        \n",
    "        cid, group = j.split(\"_\")\n",
    "        if group=='event' :\n",
    "            #df[str(IMG_ID)][(df['id']==int(cid))&(df['group']==1)] = f\n",
    "            df.loc[(df['id']==int(cid))&(df['group']==1), str(IMG_ID)] = f\n",
    "        else:\n",
    "            df.loc[(df['id']==int(cid))&(df['group']==0), str(IMG_ID)] = f\n",
    "            #df[str(IMG_ID)][(df['id']==int(cid))&(df['group']==0)] = f\n",
    "        \n",
    "        #print(df)\n",
    "    \n",
    "    for j in dataset_val.case_id:\n",
    "        img = dataset_val.load_case_image(j,IMG_ID)[0]\n",
    "        #print(img.shape)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        features = model.predict(img)\n",
    "        features = np.squeeze(features)\n",
    "        #f = np.mean(features)\n",
    "        f = np.dot(features,features.T)\n",
    "        print(f)\n",
    "        cid, group = j.split(\"_\")\n",
    "        if group=='event' :\n",
    "            #df[str(IMG_ID)][(df['id']==int(cid))&(df['group']==1)] = f\n",
    "            df.loc[(df['id']==int(cid))&(df['group']==1), str(IMG_ID)] = f\n",
    "        else:\n",
    "            df.loc[(df['id']==int(cid))&(df['group']==0), str(IMG_ID)] = f\n",
    "            #df[str(IMG_ID)][(df['id']==int(cid))&(df['group']==0)] = f\n",
    "        #print(df)\n",
    "print(df)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>score2</th>\n",
       "      <th>smallbin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>time_onset</th>\n",
       "      <th>ane_diam</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>-0.657735</td>\n",
       "      <td>1</td>\n",
       "      <td>22.656250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1102.351562</td>\n",
       "      <td>1044.341431</td>\n",
       "      <td>905.165833</td>\n",
       "      <td>767.463501</td>\n",
       "      <td>720.459473</td>\n",
       "      <td>769.864380</td>\n",
       "      <td>681.468262</td>\n",
       "      <td>830.427490</td>\n",
       "      <td>997.134399</td>\n",
       "      <td>1128.177856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>-0.260601</td>\n",
       "      <td>1</td>\n",
       "      <td>27.548209</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.640</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>752.254761</td>\n",
       "      <td>590.086853</td>\n",
       "      <td>605.288696</td>\n",
       "      <td>519.248047</td>\n",
       "      <td>477.994354</td>\n",
       "      <td>481.304565</td>\n",
       "      <td>755.368591</td>\n",
       "      <td>899.105042</td>\n",
       "      <td>887.393555</td>\n",
       "      <td>1024.538452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>-2.010208</td>\n",
       "      <td>0</td>\n",
       "      <td>25.380000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2788.779785</td>\n",
       "      <td>2951.548340</td>\n",
       "      <td>2369.336426</td>\n",
       "      <td>2509.709473</td>\n",
       "      <td>2105.216797</td>\n",
       "      <td>2087.960938</td>\n",
       "      <td>1326.935791</td>\n",
       "      <td>966.085205</td>\n",
       "      <td>1387.928101</td>\n",
       "      <td>1539.543823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-1.937681</td>\n",
       "      <td>0</td>\n",
       "      <td>29.069767</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>839.107056</td>\n",
       "      <td>1108.231934</td>\n",
       "      <td>771.404297</td>\n",
       "      <td>918.657898</td>\n",
       "      <td>864.648865</td>\n",
       "      <td>868.516663</td>\n",
       "      <td>883.539551</td>\n",
       "      <td>862.230591</td>\n",
       "      <td>1190.788574</td>\n",
       "      <td>1266.091553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.880417</td>\n",
       "      <td>0</td>\n",
       "      <td>23.875115</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1008.090698</td>\n",
       "      <td>761.508301</td>\n",
       "      <td>801.459106</td>\n",
       "      <td>641.298157</td>\n",
       "      <td>1291.407227</td>\n",
       "      <td>1541.469238</td>\n",
       "      <td>873.912537</td>\n",
       "      <td>1340.860352</td>\n",
       "      <td>1154.286377</td>\n",
       "      <td>1298.858276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.817507</td>\n",
       "      <td>1</td>\n",
       "      <td>27.379665</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1253.077881</td>\n",
       "      <td>1533.772949</td>\n",
       "      <td>1128.634644</td>\n",
       "      <td>1183.018066</td>\n",
       "      <td>1026.976685</td>\n",
       "      <td>1066.508545</td>\n",
       "      <td>902.695435</td>\n",
       "      <td>1059.049194</td>\n",
       "      <td>1001.314819</td>\n",
       "      <td>1123.367798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>-1.704438</td>\n",
       "      <td>0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1329.700806</td>\n",
       "      <td>2134.098633</td>\n",
       "      <td>1805.326904</td>\n",
       "      <td>1607.108154</td>\n",
       "      <td>1470.137085</td>\n",
       "      <td>1671.443970</td>\n",
       "      <td>1359.661621</td>\n",
       "      <td>1369.864868</td>\n",
       "      <td>1595.577881</td>\n",
       "      <td>1609.625488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>-1.705023</td>\n",
       "      <td>1</td>\n",
       "      <td>19.390582</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2228.760498</td>\n",
       "      <td>2716.164795</td>\n",
       "      <td>2189.379639</td>\n",
       "      <td>1319.701050</td>\n",
       "      <td>1730.356323</td>\n",
       "      <td>2296.951172</td>\n",
       "      <td>1039.990723</td>\n",
       "      <td>1060.238770</td>\n",
       "      <td>870.531860</td>\n",
       "      <td>1486.687256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>0</td>\n",
       "      <td>31.141869</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.980</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2777.462402</td>\n",
       "      <td>2432.452881</td>\n",
       "      <td>2282.190918</td>\n",
       "      <td>2183.297607</td>\n",
       "      <td>2143.560303</td>\n",
       "      <td>2117.976562</td>\n",
       "      <td>1872.069946</td>\n",
       "      <td>1825.354858</td>\n",
       "      <td>1700.698975</td>\n",
       "      <td>1871.333862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.025385</td>\n",
       "      <td>0</td>\n",
       "      <td>26.423570</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.600</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>838.391602</td>\n",
       "      <td>811.658813</td>\n",
       "      <td>1164.529053</td>\n",
       "      <td>1349.803467</td>\n",
       "      <td>1296.512939</td>\n",
       "      <td>1219.933594</td>\n",
       "      <td>939.769775</td>\n",
       "      <td>816.544556</td>\n",
       "      <td>960.827393</td>\n",
       "      <td>1038.667358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>-1.950741</td>\n",
       "      <td>0</td>\n",
       "      <td>29.410759</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>635.590271</td>\n",
       "      <td>1873.420654</td>\n",
       "      <td>1633.217896</td>\n",
       "      <td>2115.295898</td>\n",
       "      <td>1612.734009</td>\n",
       "      <td>1520.432007</td>\n",
       "      <td>1459.976929</td>\n",
       "      <td>1366.666992</td>\n",
       "      <td>1737.812012</td>\n",
       "      <td>1792.752686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.963092</td>\n",
       "      <td>0</td>\n",
       "      <td>24.221453</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.500</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2607.784424</td>\n",
       "      <td>2368.517822</td>\n",
       "      <td>2397.857910</td>\n",
       "      <td>1800.963501</td>\n",
       "      <td>2223.781006</td>\n",
       "      <td>2144.399658</td>\n",
       "      <td>1475.132935</td>\n",
       "      <td>1715.242920</td>\n",
       "      <td>1779.755371</td>\n",
       "      <td>1762.013916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>-1.819756</td>\n",
       "      <td>0</td>\n",
       "      <td>21.604938</td>\n",
       "      <td>120.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2163.148926</td>\n",
       "      <td>2657.654297</td>\n",
       "      <td>2926.311768</td>\n",
       "      <td>2656.722168</td>\n",
       "      <td>2157.886230</td>\n",
       "      <td>1175.445068</td>\n",
       "      <td>1895.633179</td>\n",
       "      <td>1852.876953</td>\n",
       "      <td>1496.575806</td>\n",
       "      <td>1815.737549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1.860024</td>\n",
       "      <td>0</td>\n",
       "      <td>24.910767</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.210</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1394.303101</td>\n",
       "      <td>1699.124512</td>\n",
       "      <td>1759.612061</td>\n",
       "      <td>1879.398071</td>\n",
       "      <td>1413.510986</td>\n",
       "      <td>1694.013916</td>\n",
       "      <td>1051.407837</td>\n",
       "      <td>1284.668701</td>\n",
       "      <td>1247.216553</td>\n",
       "      <td>1169.134521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.740890</td>\n",
       "      <td>0</td>\n",
       "      <td>27.681661</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.640</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1981.017822</td>\n",
       "      <td>2261.395508</td>\n",
       "      <td>1321.670532</td>\n",
       "      <td>1515.862305</td>\n",
       "      <td>1107.286133</td>\n",
       "      <td>1260.880737</td>\n",
       "      <td>1180.540039</td>\n",
       "      <td>1038.599487</td>\n",
       "      <td>1290.967285</td>\n",
       "      <td>1433.531128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.806499</td>\n",
       "      <td>0</td>\n",
       "      <td>27.681661</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1545.079224</td>\n",
       "      <td>1467.817383</td>\n",
       "      <td>1240.931763</td>\n",
       "      <td>762.956726</td>\n",
       "      <td>954.381897</td>\n",
       "      <td>1193.848755</td>\n",
       "      <td>983.691650</td>\n",
       "      <td>907.224731</td>\n",
       "      <td>965.171021</td>\n",
       "      <td>1312.084106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.816806</td>\n",
       "      <td>1</td>\n",
       "      <td>28.934069</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>978.686646</td>\n",
       "      <td>619.797363</td>\n",
       "      <td>696.041992</td>\n",
       "      <td>534.597900</td>\n",
       "      <td>1205.595703</td>\n",
       "      <td>915.694824</td>\n",
       "      <td>1017.705200</td>\n",
       "      <td>1168.574219</td>\n",
       "      <td>1432.527588</td>\n",
       "      <td>1046.837891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.670273</td>\n",
       "      <td>1</td>\n",
       "      <td>24.034610</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1579.125488</td>\n",
       "      <td>1736.832764</td>\n",
       "      <td>1457.689087</td>\n",
       "      <td>1181.402100</td>\n",
       "      <td>1528.960571</td>\n",
       "      <td>1525.934570</td>\n",
       "      <td>1392.989014</td>\n",
       "      <td>1228.102783</td>\n",
       "      <td>1622.057007</td>\n",
       "      <td>1603.551636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>-2.164651</td>\n",
       "      <td>0</td>\n",
       "      <td>23.836735</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.630</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1799.322021</td>\n",
       "      <td>1359.986694</td>\n",
       "      <td>1712.088379</td>\n",
       "      <td>1270.087769</td>\n",
       "      <td>1041.698608</td>\n",
       "      <td>1278.617920</td>\n",
       "      <td>988.042725</td>\n",
       "      <td>586.268372</td>\n",
       "      <td>598.367859</td>\n",
       "      <td>916.545105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>-2.213810</td>\n",
       "      <td>0</td>\n",
       "      <td>27.755102</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1435.162354</td>\n",
       "      <td>1083.662964</td>\n",
       "      <td>552.884216</td>\n",
       "      <td>876.411499</td>\n",
       "      <td>1022.448242</td>\n",
       "      <td>1031.486572</td>\n",
       "      <td>957.835571</td>\n",
       "      <td>878.479431</td>\n",
       "      <td>1069.298096</td>\n",
       "      <td>1075.591553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>-2.173324</td>\n",
       "      <td>1</td>\n",
       "      <td>28.734694</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1387.654907</td>\n",
       "      <td>1518.867432</td>\n",
       "      <td>1300.468506</td>\n",
       "      <td>1273.407959</td>\n",
       "      <td>902.014038</td>\n",
       "      <td>1139.929321</td>\n",
       "      <td>1122.493652</td>\n",
       "      <td>1084.568359</td>\n",
       "      <td>1256.212891</td>\n",
       "      <td>1258.040039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-2.191658</td>\n",
       "      <td>0</td>\n",
       "      <td>20.987654</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.300</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2113.895508</td>\n",
       "      <td>1785.648193</td>\n",
       "      <td>1496.517700</td>\n",
       "      <td>1284.935547</td>\n",
       "      <td>1154.084229</td>\n",
       "      <td>1232.820557</td>\n",
       "      <td>803.168457</td>\n",
       "      <td>866.054626</td>\n",
       "      <td>954.687561</td>\n",
       "      <td>1074.346191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>-1.230815</td>\n",
       "      <td>1</td>\n",
       "      <td>24.221453</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.600</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2106.542480</td>\n",
       "      <td>2196.544434</td>\n",
       "      <td>2469.492188</td>\n",
       "      <td>1589.823730</td>\n",
       "      <td>1891.581055</td>\n",
       "      <td>1731.394043</td>\n",
       "      <td>1346.396118</td>\n",
       "      <td>1189.900879</td>\n",
       "      <td>1496.183960</td>\n",
       "      <td>1680.121704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>-0.559796</td>\n",
       "      <td>1</td>\n",
       "      <td>28.400548</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1003.435547</td>\n",
       "      <td>942.295288</td>\n",
       "      <td>1147.128540</td>\n",
       "      <td>1078.111694</td>\n",
       "      <td>577.707397</td>\n",
       "      <td>703.860901</td>\n",
       "      <td>669.590576</td>\n",
       "      <td>664.069458</td>\n",
       "      <td>868.589478</td>\n",
       "      <td>711.547424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.383597</td>\n",
       "      <td>1</td>\n",
       "      <td>27.239224</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1201.903198</td>\n",
       "      <td>1077.904541</td>\n",
       "      <td>744.687317</td>\n",
       "      <td>691.346252</td>\n",
       "      <td>1230.688477</td>\n",
       "      <td>691.346252</td>\n",
       "      <td>1346.007080</td>\n",
       "      <td>987.709106</td>\n",
       "      <td>893.844666</td>\n",
       "      <td>1322.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>-1.221590</td>\n",
       "      <td>1</td>\n",
       "      <td>25.390625</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>827.523926</td>\n",
       "      <td>661.874817</td>\n",
       "      <td>1079.572144</td>\n",
       "      <td>1025.394043</td>\n",
       "      <td>1333.088379</td>\n",
       "      <td>844.468323</td>\n",
       "      <td>597.713623</td>\n",
       "      <td>671.979919</td>\n",
       "      <td>807.398987</td>\n",
       "      <td>664.771484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>-1.901623</td>\n",
       "      <td>0</td>\n",
       "      <td>21.718066</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2442.819092</td>\n",
       "      <td>2224.001709</td>\n",
       "      <td>2685.434814</td>\n",
       "      <td>2311.725098</td>\n",
       "      <td>2308.166992</td>\n",
       "      <td>2237.389404</td>\n",
       "      <td>1594.500732</td>\n",
       "      <td>1960.291748</td>\n",
       "      <td>1603.179810</td>\n",
       "      <td>1725.616821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>-1.906157</td>\n",
       "      <td>0</td>\n",
       "      <td>25.351541</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.336</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>860.629883</td>\n",
       "      <td>1090.437500</td>\n",
       "      <td>599.805664</td>\n",
       "      <td>1542.668945</td>\n",
       "      <td>1051.482422</td>\n",
       "      <td>1205.127930</td>\n",
       "      <td>910.162109</td>\n",
       "      <td>1088.623047</td>\n",
       "      <td>1354.073364</td>\n",
       "      <td>1042.692993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>-1.591389</td>\n",
       "      <td>0</td>\n",
       "      <td>21.971336</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.600</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1069.930176</td>\n",
       "      <td>742.678101</td>\n",
       "      <td>793.895752</td>\n",
       "      <td>800.590393</td>\n",
       "      <td>1170.377930</td>\n",
       "      <td>1101.189697</td>\n",
       "      <td>977.181641</td>\n",
       "      <td>831.052002</td>\n",
       "      <td>1160.083862</td>\n",
       "      <td>1306.728516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1.598571</td>\n",
       "      <td>0</td>\n",
       "      <td>24.337480</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>912.288574</td>\n",
       "      <td>1340.811157</td>\n",
       "      <td>754.270020</td>\n",
       "      <td>725.907043</td>\n",
       "      <td>549.081299</td>\n",
       "      <td>705.663330</td>\n",
       "      <td>896.849121</td>\n",
       "      <td>1070.589478</td>\n",
       "      <td>1112.210449</td>\n",
       "      <td>930.123596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.140367</td>\n",
       "      <td>1</td>\n",
       "      <td>22.204082</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.950</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1345.203247</td>\n",
       "      <td>756.372192</td>\n",
       "      <td>1651.500122</td>\n",
       "      <td>1226.438232</td>\n",
       "      <td>1072.007690</td>\n",
       "      <td>1175.462402</td>\n",
       "      <td>595.078491</td>\n",
       "      <td>700.620361</td>\n",
       "      <td>543.482300</td>\n",
       "      <td>865.255615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.563989</td>\n",
       "      <td>1</td>\n",
       "      <td>26.122449</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.300</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2243.385254</td>\n",
       "      <td>2681.055176</td>\n",
       "      <td>2206.810059</td>\n",
       "      <td>1911.371094</td>\n",
       "      <td>2149.476807</td>\n",
       "      <td>1940.644043</td>\n",
       "      <td>1536.493774</td>\n",
       "      <td>1307.436035</td>\n",
       "      <td>1457.214355</td>\n",
       "      <td>1469.718506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.097852</td>\n",
       "      <td>0</td>\n",
       "      <td>26.729928</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2585.716797</td>\n",
       "      <td>2886.518555</td>\n",
       "      <td>1900.206299</td>\n",
       "      <td>866.574463</td>\n",
       "      <td>1797.941895</td>\n",
       "      <td>805.487488</td>\n",
       "      <td>743.742981</td>\n",
       "      <td>1594.183105</td>\n",
       "      <td>1531.003296</td>\n",
       "      <td>1611.236328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-1.121745</td>\n",
       "      <td>1</td>\n",
       "      <td>27.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.360</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>777.428101</td>\n",
       "      <td>1578.418945</td>\n",
       "      <td>622.271606</td>\n",
       "      <td>559.034302</td>\n",
       "      <td>1121.130249</td>\n",
       "      <td>1311.671875</td>\n",
       "      <td>1015.551880</td>\n",
       "      <td>1073.431396</td>\n",
       "      <td>1011.009338</td>\n",
       "      <td>1121.430542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>-2.288408</td>\n",
       "      <td>1</td>\n",
       "      <td>29.903029</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1756.759644</td>\n",
       "      <td>642.225647</td>\n",
       "      <td>1589.979980</td>\n",
       "      <td>1255.641846</td>\n",
       "      <td>1470.820801</td>\n",
       "      <td>1654.052246</td>\n",
       "      <td>1408.581299</td>\n",
       "      <td>1029.892822</td>\n",
       "      <td>1039.359741</td>\n",
       "      <td>1160.135864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>-1.815946</td>\n",
       "      <td>1</td>\n",
       "      <td>27.055151</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.250</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>979.816711</td>\n",
       "      <td>939.265015</td>\n",
       "      <td>1075.802490</td>\n",
       "      <td>805.128479</td>\n",
       "      <td>688.436646</td>\n",
       "      <td>665.276245</td>\n",
       "      <td>629.147461</td>\n",
       "      <td>595.376099</td>\n",
       "      <td>621.707886</td>\n",
       "      <td>1046.487305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>-1.641087</td>\n",
       "      <td>0</td>\n",
       "      <td>30.421850</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1559.060547</td>\n",
       "      <td>1307.238281</td>\n",
       "      <td>1247.387329</td>\n",
       "      <td>1067.871216</td>\n",
       "      <td>1086.817871</td>\n",
       "      <td>1086.817871</td>\n",
       "      <td>698.473206</td>\n",
       "      <td>778.440186</td>\n",
       "      <td>967.554810</td>\n",
       "      <td>910.760864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.648182</td>\n",
       "      <td>0</td>\n",
       "      <td>23.938990</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.500</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1158.429443</td>\n",
       "      <td>900.952148</td>\n",
       "      <td>968.087646</td>\n",
       "      <td>934.386658</td>\n",
       "      <td>700.891174</td>\n",
       "      <td>686.895874</td>\n",
       "      <td>868.372803</td>\n",
       "      <td>759.324341</td>\n",
       "      <td>994.344299</td>\n",
       "      <td>996.132141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.589733</td>\n",
       "      <td>0</td>\n",
       "      <td>26.729928</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1032.249756</td>\n",
       "      <td>664.182861</td>\n",
       "      <td>1422.405518</td>\n",
       "      <td>969.983154</td>\n",
       "      <td>901.384094</td>\n",
       "      <td>1171.735718</td>\n",
       "      <td>885.419556</td>\n",
       "      <td>744.674500</td>\n",
       "      <td>890.436951</td>\n",
       "      <td>905.583008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.434553</td>\n",
       "      <td>0</td>\n",
       "      <td>31.095278</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.130</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1100.211182</td>\n",
       "      <td>743.343018</td>\n",
       "      <td>882.470215</td>\n",
       "      <td>705.570862</td>\n",
       "      <td>633.391907</td>\n",
       "      <td>995.401001</td>\n",
       "      <td>1304.492310</td>\n",
       "      <td>1196.367920</td>\n",
       "      <td>1222.318359</td>\n",
       "      <td>1355.579590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.956578</td>\n",
       "      <td>0</td>\n",
       "      <td>29.983588</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1065.447021</td>\n",
       "      <td>1465.565674</td>\n",
       "      <td>1506.189941</td>\n",
       "      <td>1492.071777</td>\n",
       "      <td>1344.671387</td>\n",
       "      <td>1196.410767</td>\n",
       "      <td>795.274536</td>\n",
       "      <td>773.046326</td>\n",
       "      <td>1113.933716</td>\n",
       "      <td>1086.857422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.707165</td>\n",
       "      <td>0</td>\n",
       "      <td>24.618104</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>824.271118</td>\n",
       "      <td>960.237793</td>\n",
       "      <td>791.208069</td>\n",
       "      <td>680.069824</td>\n",
       "      <td>1080.655518</td>\n",
       "      <td>883.365967</td>\n",
       "      <td>580.500549</td>\n",
       "      <td>591.645630</td>\n",
       "      <td>782.317688</td>\n",
       "      <td>935.852600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>-2.106903</td>\n",
       "      <td>1</td>\n",
       "      <td>22.038567</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.480</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2518.613281</td>\n",
       "      <td>2950.792725</td>\n",
       "      <td>1954.021973</td>\n",
       "      <td>2558.756836</td>\n",
       "      <td>2514.107422</td>\n",
       "      <td>2474.413330</td>\n",
       "      <td>1769.149414</td>\n",
       "      <td>1614.487793</td>\n",
       "      <td>1928.932373</td>\n",
       "      <td>1887.191895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.852128</td>\n",
       "      <td>0</td>\n",
       "      <td>22.862369</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1456.876831</td>\n",
       "      <td>2809.139404</td>\n",
       "      <td>2357.484375</td>\n",
       "      <td>2833.701172</td>\n",
       "      <td>2063.105957</td>\n",
       "      <td>2142.293213</td>\n",
       "      <td>1895.565918</td>\n",
       "      <td>1812.863281</td>\n",
       "      <td>1803.268311</td>\n",
       "      <td>2019.382324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>-1.610389</td>\n",
       "      <td>1</td>\n",
       "      <td>29.384757</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4.190</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2554.858887</td>\n",
       "      <td>1408.786865</td>\n",
       "      <td>2522.773193</td>\n",
       "      <td>2583.022949</td>\n",
       "      <td>2248.078125</td>\n",
       "      <td>2332.931396</td>\n",
       "      <td>1935.090454</td>\n",
       "      <td>2284.231689</td>\n",
       "      <td>2067.232910</td>\n",
       "      <td>2020.483154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>-0.867844</td>\n",
       "      <td>0</td>\n",
       "      <td>22.204082</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.200</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1033.621582</td>\n",
       "      <td>1031.220581</td>\n",
       "      <td>1071.932617</td>\n",
       "      <td>1121.328003</td>\n",
       "      <td>1121.328003</td>\n",
       "      <td>1002.470276</td>\n",
       "      <td>639.501221</td>\n",
       "      <td>761.698242</td>\n",
       "      <td>728.666260</td>\n",
       "      <td>1161.355591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>-2.344058</td>\n",
       "      <td>0</td>\n",
       "      <td>20.619254</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1057.158691</td>\n",
       "      <td>1072.603760</td>\n",
       "      <td>1188.118164</td>\n",
       "      <td>1045.864746</td>\n",
       "      <td>675.618469</td>\n",
       "      <td>1102.160400</td>\n",
       "      <td>545.946167</td>\n",
       "      <td>740.373840</td>\n",
       "      <td>860.974670</td>\n",
       "      <td>1192.382324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>-2.271741</td>\n",
       "      <td>0</td>\n",
       "      <td>27.732300</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.050</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1147.981567</td>\n",
       "      <td>481.009338</td>\n",
       "      <td>1653.699951</td>\n",
       "      <td>1571.898926</td>\n",
       "      <td>1423.890503</td>\n",
       "      <td>1281.628662</td>\n",
       "      <td>1364.448730</td>\n",
       "      <td>1333.810303</td>\n",
       "      <td>1391.778687</td>\n",
       "      <td>1720.265869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.698870</td>\n",
       "      <td>1</td>\n",
       "      <td>28.400548</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>987.584656</td>\n",
       "      <td>1279.754761</td>\n",
       "      <td>1221.142822</td>\n",
       "      <td>1121.004150</td>\n",
       "      <td>850.410583</td>\n",
       "      <td>819.864380</td>\n",
       "      <td>786.129883</td>\n",
       "      <td>775.132751</td>\n",
       "      <td>962.862183</td>\n",
       "      <td>1154.752686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>-1.257730</td>\n",
       "      <td>1</td>\n",
       "      <td>28.731747</td>\n",
       "      <td>240.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>760.170166</td>\n",
       "      <td>589.055908</td>\n",
       "      <td>1334.957764</td>\n",
       "      <td>1002.897034</td>\n",
       "      <td>1036.469238</td>\n",
       "      <td>974.013000</td>\n",
       "      <td>430.179626</td>\n",
       "      <td>670.255798</td>\n",
       "      <td>921.670349</td>\n",
       "      <td>1071.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>-1.707943</td>\n",
       "      <td>1</td>\n",
       "      <td>26.573129</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2955.612793</td>\n",
       "      <td>2405.721680</td>\n",
       "      <td>2063.205078</td>\n",
       "      <td>2164.208984</td>\n",
       "      <td>2159.227051</td>\n",
       "      <td>1772.235962</td>\n",
       "      <td>1671.857178</td>\n",
       "      <td>1675.205322</td>\n",
       "      <td>2027.946777</td>\n",
       "      <td>1714.399414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>-1.747033</td>\n",
       "      <td>0</td>\n",
       "      <td>26.122449</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2757.841309</td>\n",
       "      <td>2559.574951</td>\n",
       "      <td>2622.122070</td>\n",
       "      <td>2366.032227</td>\n",
       "      <td>1968.970459</td>\n",
       "      <td>2088.562012</td>\n",
       "      <td>1443.452271</td>\n",
       "      <td>1672.736938</td>\n",
       "      <td>1665.949219</td>\n",
       "      <td>1965.271362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>-2.120811</td>\n",
       "      <td>0</td>\n",
       "      <td>29.410000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2299.123047</td>\n",
       "      <td>1253.750366</td>\n",
       "      <td>1763.962891</td>\n",
       "      <td>1360.262817</td>\n",
       "      <td>1377.013672</td>\n",
       "      <td>1401.294189</td>\n",
       "      <td>1263.434326</td>\n",
       "      <td>1311.378784</td>\n",
       "      <td>1556.213379</td>\n",
       "      <td>1745.886963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.951066</td>\n",
       "      <td>0</td>\n",
       "      <td>31.887755</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.910</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2205.274902</td>\n",
       "      <td>2426.214355</td>\n",
       "      <td>2008.432861</td>\n",
       "      <td>1559.101807</td>\n",
       "      <td>1514.890015</td>\n",
       "      <td>1602.898804</td>\n",
       "      <td>1358.337036</td>\n",
       "      <td>1303.036377</td>\n",
       "      <td>865.672607</td>\n",
       "      <td>1918.738037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-2.013845</td>\n",
       "      <td>0</td>\n",
       "      <td>27.005131</td>\n",
       "      <td>168.0</td>\n",
       "      <td>4.700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2612.206055</td>\n",
       "      <td>2400.971191</td>\n",
       "      <td>2518.856689</td>\n",
       "      <td>2157.391602</td>\n",
       "      <td>1791.133667</td>\n",
       "      <td>1458.725708</td>\n",
       "      <td>2085.915039</td>\n",
       "      <td>1752.254395</td>\n",
       "      <td>2173.306152</td>\n",
       "      <td>389.626495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.378944</td>\n",
       "      <td>1</td>\n",
       "      <td>24.221453</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.800</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2534.212402</td>\n",
       "      <td>2861.734375</td>\n",
       "      <td>2570.566650</td>\n",
       "      <td>1139.843384</td>\n",
       "      <td>1823.354614</td>\n",
       "      <td>1992.907227</td>\n",
       "      <td>1866.401489</td>\n",
       "      <td>1715.240723</td>\n",
       "      <td>1621.161377</td>\n",
       "      <td>1736.735840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>-2.391192</td>\n",
       "      <td>1</td>\n",
       "      <td>20.253848</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>753.615845</td>\n",
       "      <td>1119.260254</td>\n",
       "      <td>834.432434</td>\n",
       "      <td>968.374390</td>\n",
       "      <td>750.704895</td>\n",
       "      <td>819.767761</td>\n",
       "      <td>735.362061</td>\n",
       "      <td>768.616943</td>\n",
       "      <td>725.760193</td>\n",
       "      <td>960.683228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>-2.286890</td>\n",
       "      <td>1</td>\n",
       "      <td>27.335640</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.810</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2476.531494</td>\n",
       "      <td>2602.845947</td>\n",
       "      <td>2535.599121</td>\n",
       "      <td>2225.724854</td>\n",
       "      <td>1904.966309</td>\n",
       "      <td>2061.396484</td>\n",
       "      <td>1963.867676</td>\n",
       "      <td>1823.682983</td>\n",
       "      <td>1857.630371</td>\n",
       "      <td>2399.519531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.940001</td>\n",
       "      <td>1</td>\n",
       "      <td>27.053803</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1043.856689</td>\n",
       "      <td>1047.975708</td>\n",
       "      <td>900.916138</td>\n",
       "      <td>878.185242</td>\n",
       "      <td>878.185242</td>\n",
       "      <td>1016.992981</td>\n",
       "      <td>823.143188</td>\n",
       "      <td>763.410889</td>\n",
       "      <td>1060.597900</td>\n",
       "      <td>1058.705811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.384039</td>\n",
       "      <td>1</td>\n",
       "      <td>27.343750</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>812.407043</td>\n",
       "      <td>649.641846</td>\n",
       "      <td>349.139008</td>\n",
       "      <td>1587.281860</td>\n",
       "      <td>1544.390869</td>\n",
       "      <td>1488.837646</td>\n",
       "      <td>1311.259888</td>\n",
       "      <td>1329.355225</td>\n",
       "      <td>1832.352539</td>\n",
       "      <td>1543.670776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  group  sex  age    score2  smallbin        bmi  time_onset  ane_diam  \\\n",
       "0    1      1    0   71 -0.657735         1  22.656250         7.0     5.000   \n",
       "1    1      0    0   69 -0.260601         1  27.548209        48.0     5.640   \n",
       "2    2      1    1   33 -2.010208         0  25.380000        12.0     4.700   \n",
       "3    2      0    1   28 -1.937681         0  29.069767        10.0     0.000   \n",
       "4    3      0    1   50 -0.880417         0  23.875115       168.0     0.000   \n",
       "5    3      1    1   49 -0.817507         1  27.379665        24.0     5.100   \n",
       "6    4      0    1   47 -1.704438         0  40.000000         5.0     0.000   \n",
       "7    4      1    1   53 -1.705023         1  19.390582        24.0     4.000   \n",
       "8    5      1    1   50 -0.012975         0  31.141869        24.0     4.980   \n",
       "9    5      0    1   50 -0.025385         0  26.423570         8.0     5.600   \n",
       "10   6      0    1   46 -1.950741         0  29.410759         4.0     4.400   \n",
       "11   6      1    1   50 -1.963092         0  24.221453        24.0     4.500   \n",
       "12   7      0    1   53 -1.819756         0  21.604938       120.0     6.000   \n",
       "13   7      1    1   49 -1.860024         0  24.910767        20.0     4.210   \n",
       "14   8      1    1   50 -1.740890         0  27.681661        24.0     6.640   \n",
       "15   8      0    1   48 -1.806499         0  27.681661        24.0     0.000   \n",
       "16   9      0    0   61 -0.816806         1  28.934069        48.0     0.000   \n",
       "17   9      1    0   58 -0.670273         1  24.034610         8.0     4.700   \n",
       "18  10      1    1   63 -2.164651         0  23.836735         4.0     4.630   \n",
       "19  10      0    1   58 -2.213810         0  27.755102         4.0     4.400   \n",
       "20  11      0    1   43 -2.173324         1  28.734694        24.0     0.000   \n",
       "21  11      1    1   41 -2.191658         0  20.987654        24.0     4.300   \n",
       "22  12      0    1   59 -1.230815         1  24.221453         8.0     4.600   \n",
       "23  12      1    1   62 -0.559796         1  28.400548        10.0     4.100   \n",
       "24  13      0    0   62 -1.383597         1  27.239224        96.0     0.000   \n",
       "25  13      1    0   65 -1.221590         1  25.390625        18.0     3.900   \n",
       "26  14      0    1   54 -1.901623         0  21.718066        18.0     6.000   \n",
       "27  14      1    1   47 -1.906157         0  25.351541        24.0     5.336   \n",
       "28  15      0    1   59 -1.591389         0  21.971336        24.0     5.600   \n",
       "29  15      1    1   57 -1.598571         0  24.337480        96.0     4.400   \n",
       "..  ..    ...  ...  ...       ...       ...        ...         ...       ...   \n",
       "52  27      0    1   52 -1.140367         1  22.204082        96.0     4.950   \n",
       "53  27      1    1   51  0.563989         1  26.122449        24.0     4.300   \n",
       "54  28      0    1   41 -1.097852         0  26.729928        24.0     4.000   \n",
       "55  28      1    1   39 -1.121745         1  27.777778         5.0     4.360   \n",
       "56  29      0    0   57 -2.288408         1  29.903029        96.0     4.540   \n",
       "57  29      1    0   63 -1.815946         1  27.055151        13.0     4.250   \n",
       "58  30      0    1   53 -1.641087         0  30.421850       120.0     4.100   \n",
       "59  30      1    1   52 -1.648182         0  23.938990        11.0     4.500   \n",
       "60  31      1    1   52 -1.589733         0  26.729928        12.0     0.000   \n",
       "61  31      0    1   48 -1.434553         0  31.095278        24.0     5.130   \n",
       "62  32      0    1   43 -0.956578         0  29.983588        14.0     0.000   \n",
       "63  32      1    1   37 -0.707165         0  24.618104        24.0     0.000   \n",
       "64  33      0    0   53 -2.106903         1  22.038567        72.0     5.480   \n",
       "65  33      1    0   50 -1.852128         0  22.862369        15.0     4.700   \n",
       "66  34      0    1   68 -1.610389         1  29.384757       120.0     4.190   \n",
       "67  34      1    1   68 -0.867844         0  22.204082        48.0     5.200   \n",
       "68  35      1    1   55 -2.344058         0  20.619254        72.0     0.000   \n",
       "69  35      0    1   59 -2.271741         0  27.732300        48.0     5.050   \n",
       "70  36      1    1   50 -1.698870         1  28.400548        24.0     0.000   \n",
       "71  36      0    1   52 -1.257730         1  28.731747       240.0     4.000   \n",
       "72  37      1    1   54 -1.707943         1  26.573129        24.0     4.400   \n",
       "73  37      0    1   51 -1.747033         0  26.122449        24.0     5.000   \n",
       "74  38      1    1   43 -2.120811         0  29.410000         8.0     6.400   \n",
       "75  38      0    1   41 -1.951066         0  31.887755        18.0     3.910   \n",
       "76  39      0    1   57 -2.013845         0  27.005131       168.0     4.700   \n",
       "77  39      1    1   58 -1.378944         1  24.221453        48.0     4.800   \n",
       "78  40      1    0   55 -2.391192         1  20.253848        24.0     0.000   \n",
       "79  40      0    0   49 -2.286890         1  27.335640        24.0     6.810   \n",
       "80  41      1    0   58 -1.940001         1  27.053803        12.0     0.000   \n",
       "81  41      0    0   64 -1.384039         1  27.343750        48.0     4.400   \n",
       "\n",
       "    diabetes  ...            5            6            7            8  \\\n",
       "0          1  ...  1102.351562  1044.341431   905.165833   767.463501   \n",
       "1          1  ...   752.254761   590.086853   605.288696   519.248047   \n",
       "2          0  ...  2788.779785  2951.548340  2369.336426  2509.709473   \n",
       "3          0  ...   839.107056  1108.231934   771.404297   918.657898   \n",
       "4          0  ...  1008.090698   761.508301   801.459106   641.298157   \n",
       "5          0  ...  1253.077881  1533.772949  1128.634644  1183.018066   \n",
       "6          0  ...  1329.700806  2134.098633  1805.326904  1607.108154   \n",
       "7          0  ...  2228.760498  2716.164795  2189.379639  1319.701050   \n",
       "8          0  ...  2777.462402  2432.452881  2282.190918  2183.297607   \n",
       "9          0  ...   838.391602   811.658813  1164.529053  1349.803467   \n",
       "10         0  ...   635.590271  1873.420654  1633.217896  2115.295898   \n",
       "11         0  ...  2607.784424  2368.517822  2397.857910  1800.963501   \n",
       "12         0  ...  2163.148926  2657.654297  2926.311768  2656.722168   \n",
       "13         0  ...  1394.303101  1699.124512  1759.612061  1879.398071   \n",
       "14         0  ...  1981.017822  2261.395508  1321.670532  1515.862305   \n",
       "15         0  ...  1545.079224  1467.817383  1240.931763   762.956726   \n",
       "16         1  ...   978.686646   619.797363   696.041992   534.597900   \n",
       "17         0  ...  1579.125488  1736.832764  1457.689087  1181.402100   \n",
       "18         0  ...  1799.322021  1359.986694  1712.088379  1270.087769   \n",
       "19         0  ...  1435.162354  1083.662964   552.884216   876.411499   \n",
       "20         0  ...  1387.654907  1518.867432  1300.468506  1273.407959   \n",
       "21         0  ...  2113.895508  1785.648193  1496.517700  1284.935547   \n",
       "22         0  ...  2106.542480  2196.544434  2469.492188  1589.823730   \n",
       "23         0  ...  1003.435547   942.295288  1147.128540  1078.111694   \n",
       "24         0  ...  1201.903198  1077.904541   744.687317   691.346252   \n",
       "25         0  ...   827.523926   661.874817  1079.572144  1025.394043   \n",
       "26         0  ...  2442.819092  2224.001709  2685.434814  2311.725098   \n",
       "27         0  ...   860.629883  1090.437500   599.805664  1542.668945   \n",
       "28         0  ...  1069.930176   742.678101   793.895752   800.590393   \n",
       "29         0  ...   912.288574  1340.811157   754.270020   725.907043   \n",
       "..       ...  ...          ...          ...          ...          ...   \n",
       "52         0  ...  1345.203247   756.372192  1651.500122  1226.438232   \n",
       "53         0  ...  2243.385254  2681.055176  2206.810059  1911.371094   \n",
       "54         0  ...  2585.716797  2886.518555  1900.206299   866.574463   \n",
       "55         0  ...   777.428101  1578.418945   622.271606   559.034302   \n",
       "56         0  ...  1756.759644   642.225647  1589.979980  1255.641846   \n",
       "57         0  ...   979.816711   939.265015  1075.802490   805.128479   \n",
       "58         0  ...  1559.060547  1307.238281  1247.387329  1067.871216   \n",
       "59         0  ...  1158.429443   900.952148   968.087646   934.386658   \n",
       "60         0  ...  1032.249756   664.182861  1422.405518   969.983154   \n",
       "61         0  ...  1100.211182   743.343018   882.470215   705.570862   \n",
       "62         0  ...  1065.447021  1465.565674  1506.189941  1492.071777   \n",
       "63         0  ...   824.271118   960.237793   791.208069   680.069824   \n",
       "64         0  ...  2518.613281  2950.792725  1954.021973  2558.756836   \n",
       "65         0  ...  1456.876831  2809.139404  2357.484375  2833.701172   \n",
       "66         0  ...  2554.858887  1408.786865  2522.773193  2583.022949   \n",
       "67         0  ...  1033.621582  1031.220581  1071.932617  1121.328003   \n",
       "68         0  ...  1057.158691  1072.603760  1188.118164  1045.864746   \n",
       "69         0  ...  1147.981567   481.009338  1653.699951  1571.898926   \n",
       "70         0  ...   987.584656  1279.754761  1221.142822  1121.004150   \n",
       "71         0  ...   760.170166   589.055908  1334.957764  1002.897034   \n",
       "72         0  ...  2955.612793  2405.721680  2063.205078  2164.208984   \n",
       "73         0  ...  2757.841309  2559.574951  2622.122070  2366.032227   \n",
       "74         0  ...  2299.123047  1253.750366  1763.962891  1360.262817   \n",
       "75         0  ...  2205.274902  2426.214355  2008.432861  1559.101807   \n",
       "76         0  ...  2612.206055  2400.971191  2518.856689  2157.391602   \n",
       "77         0  ...  2534.212402  2861.734375  2570.566650  1139.843384   \n",
       "78         0  ...   753.615845  1119.260254   834.432434   968.374390   \n",
       "79         0  ...  2476.531494  2602.845947  2535.599121  2225.724854   \n",
       "80         0  ...  1043.856689  1047.975708   900.916138   878.185242   \n",
       "81         1  ...   812.407043   649.641846   349.139008  1587.281860   \n",
       "\n",
       "              9           10           11           12           13  \\\n",
       "0    720.459473   769.864380   681.468262   830.427490   997.134399   \n",
       "1    477.994354   481.304565   755.368591   899.105042   887.393555   \n",
       "2   2105.216797  2087.960938  1326.935791   966.085205  1387.928101   \n",
       "3    864.648865   868.516663   883.539551   862.230591  1190.788574   \n",
       "4   1291.407227  1541.469238   873.912537  1340.860352  1154.286377   \n",
       "5   1026.976685  1066.508545   902.695435  1059.049194  1001.314819   \n",
       "6   1470.137085  1671.443970  1359.661621  1369.864868  1595.577881   \n",
       "7   1730.356323  2296.951172  1039.990723  1060.238770   870.531860   \n",
       "8   2143.560303  2117.976562  1872.069946  1825.354858  1700.698975   \n",
       "9   1296.512939  1219.933594   939.769775   816.544556   960.827393   \n",
       "10  1612.734009  1520.432007  1459.976929  1366.666992  1737.812012   \n",
       "11  2223.781006  2144.399658  1475.132935  1715.242920  1779.755371   \n",
       "12  2157.886230  1175.445068  1895.633179  1852.876953  1496.575806   \n",
       "13  1413.510986  1694.013916  1051.407837  1284.668701  1247.216553   \n",
       "14  1107.286133  1260.880737  1180.540039  1038.599487  1290.967285   \n",
       "15   954.381897  1193.848755   983.691650   907.224731   965.171021   \n",
       "16  1205.595703   915.694824  1017.705200  1168.574219  1432.527588   \n",
       "17  1528.960571  1525.934570  1392.989014  1228.102783  1622.057007   \n",
       "18  1041.698608  1278.617920   988.042725   586.268372   598.367859   \n",
       "19  1022.448242  1031.486572   957.835571   878.479431  1069.298096   \n",
       "20   902.014038  1139.929321  1122.493652  1084.568359  1256.212891   \n",
       "21  1154.084229  1232.820557   803.168457   866.054626   954.687561   \n",
       "22  1891.581055  1731.394043  1346.396118  1189.900879  1496.183960   \n",
       "23   577.707397   703.860901   669.590576   664.069458   868.589478   \n",
       "24  1230.688477   691.346252  1346.007080   987.709106   893.844666   \n",
       "25  1333.088379   844.468323   597.713623   671.979919   807.398987   \n",
       "26  2308.166992  2237.389404  1594.500732  1960.291748  1603.179810   \n",
       "27  1051.482422  1205.127930   910.162109  1088.623047  1354.073364   \n",
       "28  1170.377930  1101.189697   977.181641   831.052002  1160.083862   \n",
       "29   549.081299   705.663330   896.849121  1070.589478  1112.210449   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "52  1072.007690  1175.462402   595.078491   700.620361   543.482300   \n",
       "53  2149.476807  1940.644043  1536.493774  1307.436035  1457.214355   \n",
       "54  1797.941895   805.487488   743.742981  1594.183105  1531.003296   \n",
       "55  1121.130249  1311.671875  1015.551880  1073.431396  1011.009338   \n",
       "56  1470.820801  1654.052246  1408.581299  1029.892822  1039.359741   \n",
       "57   688.436646   665.276245   629.147461   595.376099   621.707886   \n",
       "58  1086.817871  1086.817871   698.473206   778.440186   967.554810   \n",
       "59   700.891174   686.895874   868.372803   759.324341   994.344299   \n",
       "60   901.384094  1171.735718   885.419556   744.674500   890.436951   \n",
       "61   633.391907   995.401001  1304.492310  1196.367920  1222.318359   \n",
       "62  1344.671387  1196.410767   795.274536   773.046326  1113.933716   \n",
       "63  1080.655518   883.365967   580.500549   591.645630   782.317688   \n",
       "64  2514.107422  2474.413330  1769.149414  1614.487793  1928.932373   \n",
       "65  2063.105957  2142.293213  1895.565918  1812.863281  1803.268311   \n",
       "66  2248.078125  2332.931396  1935.090454  2284.231689  2067.232910   \n",
       "67  1121.328003  1002.470276   639.501221   761.698242   728.666260   \n",
       "68   675.618469  1102.160400   545.946167   740.373840   860.974670   \n",
       "69  1423.890503  1281.628662  1364.448730  1333.810303  1391.778687   \n",
       "70   850.410583   819.864380   786.129883   775.132751   962.862183   \n",
       "71  1036.469238   974.013000   430.179626   670.255798   921.670349   \n",
       "72  2159.227051  1772.235962  1671.857178  1675.205322  2027.946777   \n",
       "73  1968.970459  2088.562012  1443.452271  1672.736938  1665.949219   \n",
       "74  1377.013672  1401.294189  1263.434326  1311.378784  1556.213379   \n",
       "75  1514.890015  1602.898804  1358.337036  1303.036377   865.672607   \n",
       "76  1791.133667  1458.725708  2085.915039  1752.254395  2173.306152   \n",
       "77  1823.354614  1992.907227  1866.401489  1715.240723  1621.161377   \n",
       "78   750.704895   819.767761   735.362061   768.616943   725.760193   \n",
       "79  1904.966309  2061.396484  1963.867676  1823.682983  1857.630371   \n",
       "80   878.185242  1016.992981   823.143188   763.410889  1060.597900   \n",
       "81  1544.390869  1488.837646  1311.259888  1329.355225  1832.352539   \n",
       "\n",
       "             14  \n",
       "0   1128.177856  \n",
       "1   1024.538452  \n",
       "2   1539.543823  \n",
       "3   1266.091553  \n",
       "4   1298.858276  \n",
       "5   1123.367798  \n",
       "6   1609.625488  \n",
       "7   1486.687256  \n",
       "8   1871.333862  \n",
       "9   1038.667358  \n",
       "10  1792.752686  \n",
       "11  1762.013916  \n",
       "12  1815.737549  \n",
       "13  1169.134521  \n",
       "14  1433.531128  \n",
       "15  1312.084106  \n",
       "16  1046.837891  \n",
       "17  1603.551636  \n",
       "18   916.545105  \n",
       "19  1075.591553  \n",
       "20  1258.040039  \n",
       "21  1074.346191  \n",
       "22  1680.121704  \n",
       "23   711.547424  \n",
       "24  1322.075562  \n",
       "25   664.771484  \n",
       "26  1725.616821  \n",
       "27  1042.692993  \n",
       "28  1306.728516  \n",
       "29   930.123596  \n",
       "..          ...  \n",
       "52   865.255615  \n",
       "53  1469.718506  \n",
       "54  1611.236328  \n",
       "55  1121.430542  \n",
       "56  1160.135864  \n",
       "57  1046.487305  \n",
       "58   910.760864  \n",
       "59   996.132141  \n",
       "60   905.583008  \n",
       "61  1355.579590  \n",
       "62  1086.857422  \n",
       "63   935.852600  \n",
       "64  1887.191895  \n",
       "65  2019.382324  \n",
       "66  2020.483154  \n",
       "67  1161.355591  \n",
       "68  1192.382324  \n",
       "69  1720.265869  \n",
       "70  1154.752686  \n",
       "71  1071.179688  \n",
       "72  1714.399414  \n",
       "73  1965.271362  \n",
       "74  1745.886963  \n",
       "75  1918.738037  \n",
       "76   389.626495  \n",
       "77  1736.735840  \n",
       "78   960.683228  \n",
       "79  2399.519531  \n",
       "80  1058.705811  \n",
       "81  1543.670776  \n",
       "\n",
       "[82 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/nikki/Documents/xyu_iterms/aorta_classification/aortaData/20191108_41对/df_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = MinMaxScaler()\n",
    "df[df.columns[2:]] = cs.fit_transform(df[df.columns[2:]])\n",
    "df[df.columns[2:]] = df[df.columns[2:]].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[2:]]\n",
    "Y = df[\"group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#选择K个最好的特征，返回选择特征后的数据\n",
    "SelectKBest(chi2, k=2).fit_transform(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['time_onset', '11', '12', '13', '14'], dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    " \n",
    "from sklearn.feature_selection import SelectKBest\n",
    " \n",
    "# 代表选择特征值的数量\n",
    " \n",
    "selectkBest=SelectKBest(\n",
    "        f_classif,\n",
    "        k=5\n",
    "        )\n",
    " \n",
    "# 选择自变量\n",
    " \n",
    "feature=X\n",
    " \n",
    "# 调用fit方法进行最好特征的选择\n",
    " \n",
    "bestFeature=selectkBest.fit_transform(\n",
    "        feature,\n",
    "        Y\n",
    "        )\n",
    " \n",
    "# 查看关键因子\n",
    "print(selectkBest.get_support())\n",
    "feature.columns[selectkBest.get_support()]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No feature in X meets the variance threshold 3.00000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-96052d854212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#方差选择法，返回值为特征选择后的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#参数threshold为方差的阈值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mVarianceThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/variance_threshold.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" (X contains only one sample)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No feature in X meets the variance threshold 3.00000"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#方差选择法，返回值为特征选择后的数据\n",
    "#参数threshold为方差的阈值\n",
    "VarianceThreshold(threshold=).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time_onset', '11'], dtype='object')\n",
      "0 0.5675\n",
      "Index(['time_onset', '11', '13'], dtype='object')\n",
      "1 0.51\n",
      "Index(['time_onset', '11', '12', '13'], dtype='object')\n",
      "2 0.5375\n",
      "Index(['time_onset', '11', '12', '13', '14'], dtype='object')\n",
      "3 0.51\n",
      "Index(['bmi', 'time_onset', '11', '12', '13', '14'], dtype='object')\n",
      "4 0.58\n",
      "Index(['bmi', 'time_onset', 'hyperlipidemia', '11', '12', '13', '14'], dtype='object')\n",
      "5 0.5425\n",
      "Index(['bmi', 'time_onset', 'hyperlipidemia', '9', '11', '12', '13', '14'], dtype='object')\n",
      "6 0.61\n",
      "Index(['bmi', 'time_onset', 'hs_cad', 'hyperlipidemia', '9', '11', '12', '13',\n",
      "       '14'],\n",
      "      dtype='object')\n",
      "7 0.6325000000000001\n",
      "Index(['bmi', 'time_onset', 'hs_cad', 'hyperlipidemia', '7', '9', '11', '12',\n",
      "       '13', '14'],\n",
      "      dtype='object')\n",
      "8 0.5700000000000001\n",
      "Index(['bmi', 'time_onset', 'hs_cad', 'hyperlipidemia', '2', '7', '9', '11',\n",
      "       '12', '13', '14'],\n",
      "      dtype='object')\n",
      "9 0.6075\n",
      "Index(['bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia', '2', '7',\n",
      "       '9', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "10 0.5575\n",
      "Index(['bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia', '2', '7',\n",
      "       '8', '9', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "11 0.585\n",
      "Index(['bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia', '2', '5',\n",
      "       '7', '8', '9', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "12 0.51\n",
      "Index(['bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia', '2', '5',\n",
      "       '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "13 0.5075000000000001\n",
      "Index(['bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia', 'SBP', '2',\n",
      "       '5', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "14 0.5375\n",
      "Index(['bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia', 'SBP', '2',\n",
      "       '4', '5', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "15 0.5349999999999999\n",
      "Index(['bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia', 'SBP',\n",
      "       'DBP', '2', '4', '5', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "16 0.5625\n",
      "Index(['score2', 'bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia',\n",
      "       'SBP', 'DBP', '2', '4', '5', '7', '8', '9', '10', '11', '12', '13',\n",
      "       '14'],\n",
      "      dtype='object')\n",
      "17 0.5475\n",
      "Index(['score2', 'bmi', 'time_onset', 'diabetes', 'hs_cad', 'hyperlipidemia',\n",
      "       'SBP', 'DBP', 'ln_ddimer', '2', '4', '5', '7', '8', '9', '10', '11',\n",
      "       '12', '13', '14'],\n",
      "      dtype='object')\n",
      "18 0.5599999999999999\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'diabetes', 'hs_cad',\n",
      "       'hyperlipidemia', 'SBP', 'DBP', 'ln_ddimer', '2', '4', '5', '7', '8',\n",
      "       '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "19 0.5725\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'diabetes', 'hs_cad',\n",
      "       'hyperlipidemia', 'SBP', 'DBP', 'ln_ddimer', '2', '4', '5', '6', '7',\n",
      "       '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "20 0.635\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'diabetes', 'hs_cad',\n",
      "       'hyperlipidemia', 'SBP', 'DBP', 'ECG', 'ln_ddimer', '2', '4', '5', '6',\n",
      "       '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "21 0.5725\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'diabetes', 'hs_cad',\n",
      "       'hyperlipidemia', 'SBP', 'DBP', 'ECG', 'ln_ddimer', '2', '3', '4', '5',\n",
      "       '6', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "22 0.585\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam', 'diabetes',\n",
      "       'hs_cad', 'hyperlipidemia', 'SBP', 'DBP', 'ECG', 'ln_ddimer', '2', '3',\n",
      "       '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "23 0.575\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam', 'diabetes',\n",
      "       'hs_cad', 'hyperlipidemia', 'SBP', 'DBP', 'ECG', 'ln_ddimer',\n",
      "       'limb_ischemia', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
      "       '12', '13', '14'],\n",
      "      dtype='object')\n",
      "24 0.575\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam', 'diabetes',\n",
      "       'hs_cad', 'hyperlipidemia', 'SBP', 'DBP', 'ECG', 'ln_ddimer',\n",
      "       'limb_ischemia', 'tamponade_presurgbin', '2', '3', '4', '5', '6', '7',\n",
      "       '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "25 0.5725\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam', 'diabetes',\n",
      "       'hs_cad', 'hyperlipidemia', 'SBP', 'DBP', 'ECG', 'ln_ddimer',\n",
      "       'limb_ischemia', 'tamponade_presurgbin', '1', '2', '3', '4', '5', '6',\n",
      "       '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "26 0.575\n",
      "Index(['score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam', 'diabetes',\n",
      "       'hs_cad', 'hyperlipidemia', 'HBP', 'SBP', 'DBP', 'ECG', 'ln_ddimer',\n",
      "       'limb_ischemia', 'tamponade_presurgbin', '1', '2', '3', '4', '5', '6',\n",
      "       '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "27 0.5875\n",
      "Index(['age', 'score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam',\n",
      "       'diabetes', 'hs_cad', 'hyperlipidemia', 'HBP', 'SBP', 'DBP', 'ECG',\n",
      "       'ln_ddimer', 'limb_ischemia', 'tamponade_presurgbin', '1', '2', '3',\n",
      "       '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
      "      dtype='object')\n",
      "28 0.5974999999999999\n",
      "Index(['age', 'score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam',\n",
      "       'diabetes', 'hs_cad', 'hyperlipidemia', 'HBP', 'SBP', 'DBP', 'ECG',\n",
      "       'kidney_failure', 'ln_ddimer', 'limb_ischemia', 'tamponade_presurgbin',\n",
      "       '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
      "       '14'],\n",
      "      dtype='object')\n",
      "29 0.5875\n",
      "Index(['sex', 'age', 'score2', 'smallbin', 'bmi', 'time_onset', 'ane_diam',\n",
      "       'diabetes', 'hs_cad', 'hyperlipidemia', 'HBP', 'SBP', 'DBP', 'ECG',\n",
      "       'kidney_failure', 'ln_ddimer', 'limb_ischemia', 'tamponade_presurgbin',\n",
      "       '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
      "       '14'],\n",
      "      dtype='object')\n",
      "30 0.5599999999999999\n"
     ]
    }
   ],
   "source": [
    "for k in range(31):\n",
    "    selectkBest=SelectKBest(f_classif,k=k+2)\n",
    " \n",
    "    # 选择自变量\n",
    " \n",
    "    feature=X\n",
    " \n",
    "    # 调用fit方法进行最好特征的选择\n",
    " \n",
    "    bestFeature=selectkBest.fit_transform(feature, Y)\n",
    " \n",
    "    # 查看关键因子\n",
    "    #print(selectkBest.get_support())\n",
    "    print(feature.columns[selectkBest.get_support()])\n",
    "    #for i in range(30):\n",
    "    gbdt=GradientBoostingClassifier(n_estimators=100, max_depth=4)\n",
    "    score = cross_val_score(gbdt, X[feature.columns[selectkBest.get_support()]], Y, cv=10, scoring='accuracy')\n",
    "    print(k, score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6125\n"
     ]
    }
   ],
   "source": [
    "gbdt=GradientBoostingClassifier(n_estimators=30, max_depth=4, max_features=5)\n",
    "score = cross_val_score(gbdt, X[feature.columns[selectkBest.get_support()]], Y, cv=5, scoring='accuracy')\n",
    "print( score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.800  0.750         0.750  0.875  0.875  0.875  0.875  0.5  0.625\n",
      "1  0.875  0.750  0.750         0.625  0.750  0.875  0.750  0.625  0.5  0.625\n",
      "2  0.875  0.625  0.625         0.625  0.750  0.750  0.625  0.625  0.5  0.625\n",
      "3  0.750  0.625  0.625         0.500  0.750  0.750  0.625  0.625  0.5  0.600\n",
      "4  0.750  0.625  0.625         0.500  0.625  0.750  0.625  0.625  0.5  0.500\n",
      "5  0.625  0.625  0.625         0.500  0.625  0.625  0.625  0.625  0.5  0.500\n",
      "6  0.625  0.625  0.500         0.500  0.600  0.625  0.625  0.500  0.5  0.500\n",
      "7  0.625  0.500  0.500         0.500  0.500  0.625  0.500  0.500  0.5  0.375\n",
      "8  0.625  0.500  0.500         0.375  0.500  0.500  0.500  0.500  0.5  0.250\n",
      "9  0.500  0.500  0.500         0.375  0.250  0.500  0.500  0.500  0.5  0.125\n",
      "2 个特征按照accuracy进行排序\n",
      "glm             0.7125\n",
      "lda             0.6875\n",
      "qda             0.6250\n",
      "knn             0.6225\n",
      "tree            0.6175\n",
      "gnb             0.6000\n",
      "svm             0.6000\n",
      "RandomForest    0.5250\n",
      "mbp             0.5000\n",
      "ada             0.4725\n",
      "dtype: float64\n",
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.875  0.750         0.875  0.875  0.875  0.875  0.875  0.875  0.750\n",
      "1  0.750  0.875  0.750         0.625  0.875  0.750  0.750  0.750  0.875  0.625\n",
      "2  0.750  0.750  0.750         0.625  0.750  0.750  0.625  0.750  0.750  0.625\n",
      "3  0.750  0.625  0.625         0.625  0.750  0.750  0.625  0.625  0.750  0.500\n",
      "4  0.625  0.625  0.625         0.500  0.750  0.625  0.625  0.625  0.750  0.500\n",
      "5  0.625  0.500  0.625         0.500  0.625  0.625  0.500  0.625  0.750  0.500\n",
      "6  0.625  0.500  0.500         0.500  0.625  0.625  0.500  0.625  0.750  0.500\n",
      "7  0.625  0.375  0.500         0.375  0.500  0.625  0.500  0.625  0.500  0.500\n",
      "8  0.625  0.375  0.500         0.375  0.500  0.625  0.500  0.600  0.500  0.375\n",
      "9  0.600  0.250  0.500         0.250  0.375  0.500  0.500  0.500  0.375  0.125\n",
      "3 个特征按照accuracy进行排序\n",
      "mbp             0.6875\n",
      "glm             0.6850\n",
      "lda             0.6750\n",
      "knn             0.6625\n",
      "gnb             0.6600\n",
      "svm             0.6125\n",
      "qda             0.6000\n",
      "tree            0.5750\n",
      "RandomForest    0.5250\n",
      "ada             0.5000\n",
      "dtype: float64\n",
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.700  0.875  0.875  0.750  0.875  0.875  0.875\n",
      "1  0.750  0.750  0.750         0.625  0.875  0.750  0.750  0.750  0.750  0.750\n",
      "2  0.750  0.625  0.625         0.625  0.750  0.750  0.750  0.625  0.750  0.700\n",
      "3  0.750  0.625  0.625         0.625  0.750  0.750  0.625  0.625  0.750  0.625\n",
      "4  0.625  0.600  0.625         0.625  0.750  0.625  0.625  0.625  0.625  0.625\n",
      "5  0.625  0.500  0.600         0.375  0.625  0.625  0.625  0.625  0.625  0.625\n",
      "6  0.625  0.500  0.500         0.375  0.600  0.625  0.500  0.625  0.500  0.500\n",
      "7  0.625  0.375  0.500         0.375  0.500  0.625  0.500  0.625  0.500  0.500\n",
      "8  0.500  0.375  0.500         0.375  0.500  0.625  0.500  0.600  0.500  0.500\n",
      "9  0.500  0.375  0.500         0.250  0.250  0.500  0.400  0.500  0.375  0.375\n",
      "4 个特征按照accuracy进行排序\n",
      "lda             0.6750\n",
      "glm             0.6625\n",
      "gnb             0.6475\n",
      "knn             0.6475\n",
      "mbp             0.6250\n",
      "svm             0.6100\n",
      "ada             0.6075\n",
      "qda             0.6025\n",
      "tree            0.5475\n",
      "RandomForest    0.4950\n",
      "dtype: float64\n",
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.750  0.750  0.875         0.875  0.875  0.875  0.750  0.875  0.750  0.875\n",
      "1  0.750  0.625  0.750         0.750  0.750  0.750  0.750  0.750  0.750  0.800\n",
      "2  0.750  0.600  0.625         0.700  0.750  0.750  0.625  0.750  0.750  0.625\n",
      "3  0.750  0.500  0.625         0.625  0.625  0.750  0.625  0.750  0.625  0.625\n",
      "4  0.625  0.500  0.625         0.625  0.625  0.750  0.500  0.750  0.625  0.625\n",
      "5  0.625  0.375  0.625         0.625  0.625  0.750  0.500  0.625  0.625  0.500\n",
      "6  0.625  0.375  0.600         0.500  0.500  0.625  0.500  0.625  0.625  0.375\n",
      "7  0.500  0.375  0.500         0.500  0.400  0.625  0.500  0.625  0.600  0.375\n",
      "8  0.500  0.375  0.500         0.375  0.250  0.500  0.500  0.600  0.500  0.375\n",
      "9  0.500  0.125  0.500         0.375  0.250  0.375  0.300  0.500  0.375  0.375\n",
      "5 个特征按照accuracy进行排序\n",
      "gnb             0.6850\n",
      "lda             0.6750\n",
      "glm             0.6375\n",
      "mbp             0.6225\n",
      "svm             0.6225\n",
      "RandomForest    0.5950\n",
      "knn             0.5650\n",
      "ada             0.5550\n",
      "qda             0.5550\n",
      "tree            0.4600\n",
      "dtype: float64\n",
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.750  0.750         0.750  0.875  0.875  0.750  0.875  0.5  0.800\n",
      "1  0.750  0.625  0.750         0.750  0.750  0.750  0.750  0.750  0.5  0.750\n",
      "2  0.750  0.625  0.750         0.750  0.750  0.750  0.625  0.750  0.5  0.625\n",
      "3  0.625  0.600  0.625         0.750  0.625  0.750  0.625  0.750  0.5  0.625\n",
      "4  0.625  0.500  0.625         0.625  0.625  0.750  0.500  0.750  0.5  0.625\n",
      "5  0.625  0.500  0.625         0.625  0.625  0.625  0.500  0.625  0.5  0.500\n",
      "6  0.625  0.500  0.500         0.625  0.625  0.625  0.500  0.625  0.5  0.500\n",
      "7  0.600  0.500  0.500         0.600  0.500  0.600  0.375  0.600  0.5  0.500\n",
      "8  0.500  0.250  0.500         0.500  0.500  0.500  0.375  0.500  0.5  0.500\n",
      "9  0.375  0.250  0.500         0.375  0.375  0.500  0.300  0.375  0.5  0.375\n",
      "6 个特征按照accuracy进行排序\n",
      "lda             0.6725\n",
      "gnb             0.6600\n",
      "RandomForest    0.6350\n",
      "glm             0.6350\n",
      "knn             0.6250\n",
      "svm             0.6125\n",
      "ada             0.5800\n",
      "qda             0.5300\n",
      "tree            0.5100\n",
      "mbp             0.5000\n",
      "dtype: float64\n",
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.750  0.625  0.750         0.875  0.750  0.750  0.875  0.750  0.5  0.750\n",
      "1  0.750  0.625  0.750         0.800  0.750  0.750  0.750  0.750  0.5  0.700\n",
      "2  0.750  0.625  0.625         0.750  0.750  0.750  0.750  0.750  0.5  0.625\n",
      "3  0.750  0.625  0.625         0.625  0.750  0.750  0.750  0.750  0.5  0.500\n",
      "4  0.700  0.500  0.625         0.625  0.750  0.750  0.625  0.750  0.5  0.500\n",
      "5  0.625  0.500  0.625         0.625  0.625  0.700  0.625  0.750  0.5  0.500\n",
      "6  0.625  0.500  0.625         0.625  0.625  0.625  0.500  0.625  0.5  0.500\n",
      "7  0.625  0.400  0.625         0.500  0.500  0.625  0.500  0.600  0.5  0.500\n",
      "8  0.500  0.375  0.625         0.500  0.500  0.625  0.500  0.500  0.5  0.500\n",
      "9  0.250  0.375  0.600         0.375  0.500  0.250  0.375  0.375  0.5  0.250\n",
      "7 个特征按照accuracy进行排序\n",
      "gnb             0.6600\n",
      "lda             0.6575\n",
      "knn             0.6500\n",
      "svm             0.6475\n",
      "glm             0.6325\n",
      "RandomForest    0.6300\n",
      "qda             0.6250\n",
      "ada             0.5325\n",
      "tree            0.5150\n",
      "mbp             0.5000\n",
      "dtype: float64\n",
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.750  0.750  0.750         0.750  0.875  0.750  0.750  0.750  0.5  0.750\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.750  0.750  0.5  0.625\n",
      "2  0.750  0.750  0.625         0.750  0.750  0.750  0.750  0.750  0.5  0.625\n",
      "3  0.750  0.750  0.625         0.700  0.750  0.750  0.750  0.750  0.5  0.625\n",
      "4  0.625  0.625  0.625         0.625  0.750  0.750  0.750  0.750  0.5  0.625\n",
      "5  0.625  0.625  0.625         0.625  0.625  0.625  0.625  0.750  0.5  0.600\n",
      "6  0.625  0.625  0.625         0.625  0.625  0.625  0.500  0.625  0.5  0.500\n",
      "7  0.600  0.600  0.625         0.500  0.600  0.625  0.500  0.500  0.5  0.500\n",
      "8  0.500  0.500  0.625         0.500  0.500  0.600  0.400  0.500  0.5  0.375\n",
      "9  0.375  0.375  0.600         0.375  0.500  0.250  0.375  0.375  0.5  0.375\n",
      "8 个特征按照accuracy进行排序\n",
      "knn             0.6725\n",
      "gnb             0.6500\n",
      "lda             0.6475\n",
      "svm             0.6475\n",
      "tree            0.6350\n",
      "glm             0.6350\n",
      "RandomForest    0.6200\n",
      "qda             0.6150\n",
      "ada             0.5600\n",
      "mbp             0.5000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.750  0.750  0.750         0.750  0.875  0.750  0.625  0.875  0.750  0.875\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.625  0.750  0.750  0.800\n",
      "2  0.750  0.750  0.750         0.750  0.750  0.750  0.625  0.625  0.750  0.625\n",
      "3  0.750  0.625  0.750         0.750  0.750  0.750  0.625  0.500  0.750  0.625\n",
      "4  0.750  0.625  0.625         0.700  0.750  0.625  0.500  0.500  0.625  0.625\n",
      "5  0.750  0.625  0.625         0.625  0.625  0.625  0.500  0.500  0.625  0.625\n",
      "6  0.625  0.625  0.625         0.625  0.625  0.625  0.500  0.500  0.625  0.500\n",
      "7  0.625  0.500  0.625         0.625  0.625  0.625  0.500  0.500  0.625  0.500\n",
      "8  0.600  0.500  0.625         0.500  0.500  0.600  0.500  0.500  0.500  0.500\n",
      "9  0.375  0.250  0.600         0.250  0.500  0.375  0.375  0.500  0.500  0.375\n",
      "9 个特征按照accuracy进行排序\n",
      "knn             0.6750\n",
      "svm             0.6725\n",
      "glm             0.6725\n",
      "mbp             0.6500\n",
      "lda             0.6475\n",
      "RandomForest    0.6325\n",
      "ada             0.6050\n",
      "tree            0.6000\n",
      "gnb             0.5750\n",
      "qda             0.5375\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.750  0.875  0.750         0.750  0.750  0.750  0.875  0.875  0.750  0.875\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.750  0.750  0.750  0.750\n",
      "2  0.750  0.750  0.750         0.750  0.750  0.750  0.750  0.625  0.750  0.625\n",
      "3  0.750  0.700  0.625         0.750  0.625  0.750  0.625  0.500  0.750  0.625\n",
      "4  0.750  0.625  0.625         0.700  0.625  0.750  0.625  0.500  0.750  0.625\n",
      "5  0.750  0.625  0.625         0.625  0.500  0.625  0.600  0.500  0.750  0.625\n",
      "6  0.625  0.625  0.625         0.625  0.500  0.625  0.500  0.500  0.625  0.625\n",
      "7  0.625  0.500  0.625         0.625  0.500  0.600  0.500  0.500  0.625  0.600\n",
      "8  0.600  0.500  0.625         0.625  0.500  0.500  0.375  0.500  0.600  0.500\n",
      "9  0.375  0.250  0.600         0.375  0.500  0.375  0.250  0.500  0.500  0.375\n",
      "10 个特征按照accuracy进行排序\n",
      "mbp             0.6850\n",
      "glm             0.6725\n",
      "svm             0.6600\n",
      "RandomForest    0.6575\n",
      "lda             0.6475\n",
      "ada             0.6225\n",
      "tree            0.6200\n",
      "knn             0.6000\n",
      "qda             0.5850\n",
      "gnb             0.5750\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.750  0.750  0.750         0.875  0.750  0.750  0.625  0.875  0.5  0.875\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.625  0.750  0.5  0.800\n",
      "2  0.750  0.750  0.750         0.750  0.625  0.750  0.625  0.625  0.5  0.750\n",
      "3  0.750  0.700  0.750         0.625  0.625  0.750  0.625  0.500  0.5  0.750\n",
      "4  0.750  0.625  0.625         0.625  0.625  0.750  0.625  0.500  0.5  0.625\n",
      "5  0.625  0.625  0.625         0.625  0.625  0.625  0.625  0.500  0.5  0.625\n",
      "6  0.625  0.625  0.625         0.600  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "7  0.625  0.625  0.625         0.500  0.500  0.600  0.500  0.500  0.5  0.500\n",
      "8  0.600  0.500  0.625         0.500  0.500  0.500  0.500  0.500  0.5  0.500\n",
      "9  0.375  0.250  0.500         0.500  0.250  0.375  0.500  0.500  0.5  0.375\n",
      "11 个特征按照accuracy进行排序\n",
      "svm             0.6625\n",
      "glm             0.6600\n",
      "lda             0.6475\n",
      "RandomForest    0.6350\n",
      "ada             0.6300\n",
      "tree            0.6200\n",
      "knn             0.5875\n",
      "gnb             0.5750\n",
      "qda             0.5750\n",
      "mbp             0.5000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.875  0.875         0.750  0.875  0.750  0.750  1.000  0.875  0.875\n",
      "1  0.750  0.750  0.875         0.750  0.750  0.750  0.625  0.750  0.875  0.750\n",
      "2  0.750  0.750  0.750         0.625  0.625  0.750  0.625  0.625  0.750  0.750\n",
      "3  0.750  0.750  0.750         0.625  0.625  0.750  0.600  0.625  0.750  0.500\n",
      "4  0.750  0.700  0.625         0.625  0.625  0.750  0.500  0.500  0.750  0.500\n",
      "5  0.625  0.625  0.625         0.625  0.625  0.625  0.500  0.500  0.625  0.500\n",
      "6  0.625  0.625  0.625         0.600  0.625  0.625  0.500  0.500  0.625  0.400\n",
      "7  0.625  0.500  0.625         0.500  0.500  0.500  0.500  0.500  0.625  0.375\n",
      "8  0.400  0.500  0.625         0.375  0.500  0.500  0.500  0.500  0.500  0.375\n",
      "9  0.375  0.500  0.500         0.375  0.375  0.375  0.500  0.500  0.400  0.375\n",
      "12 个特征按照accuracy进行排序\n",
      "svm             0.6875\n",
      "mbp             0.6775\n",
      "tree            0.6575\n",
      "glm             0.6525\n",
      "lda             0.6375\n",
      "knn             0.6125\n",
      "gnb             0.6000\n",
      "RandomForest    0.5850\n",
      "qda             0.5600\n",
      "ada             0.5400\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.875  0.875         0.875  0.750  0.875  0.750  1.000  0.5  0.875\n",
      "1  0.750  0.750  0.875         0.750  0.750  0.750  0.625  0.750  0.5  0.875\n",
      "2  0.750  0.750  0.750         0.750  0.750  0.750  0.625  0.625  0.5  0.625\n",
      "3  0.750  0.625  0.750         0.750  0.625  0.750  0.625  0.500  0.5  0.625\n",
      "4  0.750  0.625  0.625         0.625  0.625  0.625  0.625  0.500  0.5  0.625\n",
      "5  0.625  0.625  0.625         0.625  0.625  0.625  0.500  0.500  0.5  0.600\n",
      "6  0.625  0.500  0.625         0.625  0.500  0.625  0.500  0.500  0.5  0.375\n",
      "7  0.500  0.500  0.625         0.625  0.500  0.500  0.500  0.500  0.5  0.375\n",
      "8  0.400  0.400  0.625         0.500  0.400  0.400  0.400  0.500  0.5  0.375\n",
      "9  0.375  0.250  0.500         0.375  0.375  0.375  0.375  0.500  0.5  0.250\n",
      "13 个特征按照accuracy进行排序\n",
      "svm             0.6875\n",
      "RandomForest    0.6500\n",
      "glm             0.6400\n",
      "lda             0.6275\n",
      "knn             0.5900\n",
      "tree            0.5900\n",
      "gnb             0.5875\n",
      "ada             0.5600\n",
      "qda             0.5525\n",
      "mbp             0.5000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.750  0.750  0.875  0.875  1.000  1.000  0.750\n",
      "1  0.750  0.750  0.875         0.750  0.750  0.750  0.625  0.750  0.750  0.750\n",
      "2  0.750  0.750  0.875         0.750  0.750  0.750  0.625  0.625  0.750  0.625\n",
      "3  0.750  0.625  0.750         0.750  0.750  0.750  0.625  0.625  0.750  0.625\n",
      "4  0.625  0.625  0.625         0.750  0.625  0.625  0.625  0.500  0.625  0.625\n",
      "5  0.625  0.625  0.625         0.750  0.500  0.625  0.500  0.500  0.625  0.600\n",
      "6  0.625  0.625  0.625         0.625  0.500  0.500  0.500  0.500  0.500  0.500\n",
      "7  0.500  0.625  0.625         0.625  0.500  0.500  0.500  0.500  0.500  0.375\n",
      "8  0.400  0.600  0.625         0.625  0.500  0.400  0.500  0.500  0.500  0.375\n",
      "9  0.375  0.500  0.500         0.500  0.400  0.375  0.400  0.500  0.300  0.250\n",
      "14 个特征按照accuracy进行排序\n",
      "svm             0.7000\n",
      "RandomForest    0.6875\n",
      "tree            0.6475\n",
      "mbp             0.6300\n",
      "glm             0.6275\n",
      "lda             0.6150\n",
      "knn             0.6025\n",
      "gnb             0.6000\n",
      "qda             0.5775\n",
      "ada             0.5475\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.875  0.875         0.750  0.750  0.875  1.000  1.000  0.750  0.750\n",
      "1  0.750  0.750  0.875         0.750  0.750  0.750  0.625  0.750  0.750  0.750\n",
      "2  0.625  0.625  0.750         0.625  0.750  0.750  0.625  0.625  0.625  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.750  0.500  0.625  0.625  0.625\n",
      "4  0.625  0.625  0.625         0.625  0.500  0.750  0.500  0.500  0.625  0.625\n",
      "5  0.625  0.625  0.625         0.625  0.500  0.625  0.500  0.500  0.625  0.500\n",
      "6  0.625  0.625  0.625         0.625  0.500  0.625  0.500  0.500  0.625  0.500\n",
      "7  0.625  0.500  0.625         0.500  0.500  0.500  0.500  0.500  0.500  0.500\n",
      "8  0.500  0.375  0.625         0.500  0.500  0.500  0.500  0.500  0.500  0.400\n",
      "9  0.375  0.375  0.500         0.375  0.375  0.375  0.375  0.500  0.300  0.250\n",
      "15 个特征按照accuracy进行排序\n",
      "svm             0.6875\n",
      "lda             0.6500\n",
      "glm             0.6250\n",
      "gnb             0.6000\n",
      "RandomForest    0.6000\n",
      "tree            0.6000\n",
      "mbp             0.5925\n",
      "knn             0.5875\n",
      "qda             0.5625\n",
      "ada             0.5525\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.875  0.875         0.875  0.750  0.875  0.750  1.000  0.5  0.875\n",
      "1  0.750  0.875  0.875         0.875  0.750  0.875  0.750  0.750  0.5  0.750\n",
      "2  0.750  0.625  0.750         0.750  0.750  0.750  0.625  0.625  0.5  0.750\n",
      "3  0.625  0.500  0.750         0.625  0.750  0.750  0.625  0.625  0.5  0.750\n",
      "4  0.625  0.500  0.625         0.625  0.750  0.750  0.625  0.500  0.5  0.625\n",
      "5  0.625  0.500  0.625         0.625  0.625  0.625  0.500  0.500  0.5  0.600\n",
      "6  0.625  0.500  0.625         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "7  0.625  0.500  0.625         0.625  0.500  0.500  0.400  0.500  0.5  0.500\n",
      "8  0.500  0.400  0.500         0.500  0.500  0.500  0.375  0.500  0.5  0.500\n",
      "9  0.375  0.375  0.500         0.375  0.375  0.375  0.375  0.500  0.5  0.375\n",
      "16 个特征按照accuracy进行排序\n",
      "svm             0.6750\n",
      "lda             0.6625\n",
      "RandomForest    0.6500\n",
      "knn             0.6375\n",
      "glm             0.6375\n",
      "ada             0.6225\n",
      "gnb             0.6000\n",
      "tree            0.5650\n",
      "qda             0.5525\n",
      "mbp             0.5000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.875  0.875         0.875  0.750  0.875  0.750  1.000  0.875  0.750\n",
      "1  0.750  0.750  0.875         0.750  0.750  0.875  0.750  0.750  0.875  0.625\n",
      "2  0.625  0.750  0.750         0.750  0.750  0.750  0.750  0.625  0.750  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.625  0.625  0.625  0.750  0.500\n",
      "4  0.625  0.625  0.750         0.625  0.750  0.625  0.625  0.500  0.625  0.500\n",
      "5  0.625  0.600  0.625         0.625  0.625  0.625  0.500  0.500  0.625  0.500\n",
      "6  0.500  0.500  0.625         0.500  0.625  0.600  0.500  0.500  0.625  0.500\n",
      "7  0.500  0.500  0.625         0.500  0.500  0.500  0.500  0.500  0.500  0.500\n",
      "8  0.500  0.500  0.500         0.500  0.500  0.500  0.375  0.500  0.500  0.250\n",
      "9  0.250  0.375  0.400         0.500  0.375  0.250  0.300  0.500  0.400  0.125\n",
      "17 个特征按照accuracy进行排序\n",
      "svm             0.6775\n",
      "mbp             0.6525\n",
      "knn             0.6375\n",
      "RandomForest    0.6250\n",
      "lda             0.6225\n",
      "tree            0.6100\n",
      "gnb             0.6000\n",
      "glm             0.5875\n",
      "qda             0.5675\n",
      "ada             0.4875\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.750  0.750  0.875  0.750  1.000  0.750  0.875\n",
      "1  0.750  0.625  0.750         0.750  0.750  0.875  0.750  0.750  0.750  0.750\n",
      "2  0.625  0.625  0.750         0.625  0.750  0.750  0.750  0.625  0.625  0.750\n",
      "3  0.625  0.500  0.750         0.625  0.625  0.625  0.625  0.625  0.625  0.625\n",
      "4  0.625  0.500  0.750         0.625  0.625  0.625  0.625  0.500  0.500  0.600\n",
      "5  0.500  0.500  0.750         0.625  0.625  0.625  0.500  0.500  0.500  0.500\n",
      "6  0.500  0.500  0.625         0.500  0.625  0.500  0.500  0.500  0.500  0.500\n",
      "7  0.500  0.375  0.625         0.500  0.625  0.500  0.500  0.500  0.375  0.375\n",
      "8  0.500  0.375  0.500         0.500  0.500  0.500  0.500  0.500  0.375  0.375\n",
      "9  0.250  0.375  0.400         0.500  0.375  0.250  0.375  0.500  0.375  0.250\n",
      "18 个特征按照accuracy进行排序\n",
      "svm             0.6775\n",
      "knn             0.6250\n",
      "lda             0.6125\n",
      "gnb             0.6000\n",
      "RandomForest    0.6000\n",
      "qda             0.5875\n",
      "glm             0.5750\n",
      "ada             0.5600\n",
      "mbp             0.5375\n",
      "tree            0.5125\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.750  0.625  0.875         0.750  0.750  0.875  0.875  1.000  0.875  0.875\n",
      "1  0.750  0.625  0.750         0.750  0.750  0.750  0.750  0.750  0.875  0.750\n",
      "2  0.625  0.625  0.750         0.625  0.750  0.625  0.625  0.625  0.750  0.750\n",
      "3  0.625  0.625  0.750         0.625  0.625  0.625  0.625  0.625  0.625  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.625  0.500  0.625  0.625\n",
      "5  0.600  0.500  0.750         0.625  0.625  0.625  0.625  0.500  0.625  0.500\n",
      "6  0.500  0.500  0.750         0.500  0.625  0.600  0.500  0.500  0.600  0.500\n",
      "7  0.500  0.400  0.625         0.500  0.500  0.500  0.500  0.500  0.500  0.375\n",
      "8  0.500  0.375  0.500         0.500  0.500  0.500  0.500  0.500  0.500  0.250\n",
      "9  0.250  0.375  0.300         0.375  0.375  0.375  0.250  0.500  0.250  0.250\n",
      "19 个特征按照accuracy进行排序\n",
      "svm             0.6800\n",
      "mbp             0.6225\n",
      "knn             0.6125\n",
      "lda             0.6100\n",
      "gnb             0.6000\n",
      "qda             0.5875\n",
      "RandomForest    0.5875\n",
      "glm             0.5725\n",
      "ada             0.5500\n",
      "tree            0.5275\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.875  0.875         0.875  0.750  0.875  0.750  1.000  0.5  0.625\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.875  0.625  0.750  0.5  0.625\n",
      "2  0.625  0.625  0.750         0.750  0.750  0.625  0.500  0.625  0.5  0.625\n",
      "3  0.625  0.625  0.750         0.750  0.625  0.625  0.500  0.625  0.5  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "5  0.625  0.500  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.375\n",
      "6  0.600  0.500  0.625         0.625  0.625  0.500  0.500  0.500  0.5  0.375\n",
      "7  0.500  0.500  0.625         0.500  0.625  0.500  0.500  0.500  0.5  0.300\n",
      "8  0.375  0.500  0.500         0.300  0.625  0.500  0.400  0.500  0.5  0.250\n",
      "9  0.250  0.375  0.300         0.250  0.600  0.250  0.375  0.500  0.5  0.250\n",
      "20 个特征按照accuracy进行排序\n",
      "svm             0.6675\n",
      "knn             0.6600\n",
      "RandomForest    0.6050\n",
      "gnb             0.6000\n",
      "lda             0.6000\n",
      "tree            0.5875\n",
      "glm             0.5850\n",
      "qda             0.5150\n",
      "mbp             0.5000\n",
      "ada             0.4550\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.750  0.750  0.875         0.750  0.875  0.750  0.750  1.000  0.875  0.625\n",
      "1  0.750  0.750  0.750         0.750  0.875  0.750  0.600  0.750  0.875  0.625\n",
      "2  0.625  0.750  0.750         0.750  0.750  0.625  0.500  0.625  0.750  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.625  0.500  0.625  0.750  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.750  0.625  0.500  0.500  0.625  0.500\n",
      "5  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.500  0.375\n",
      "6  0.500  0.500  0.625         0.625  0.625  0.625  0.500  0.500  0.500  0.375\n",
      "7  0.500  0.500  0.500         0.375  0.625  0.600  0.375  0.500  0.500  0.300\n",
      "8  0.375  0.500  0.500         0.375  0.500  0.375  0.375  0.500  0.250  0.250\n",
      "9  0.250  0.300  0.300         0.300  0.500  0.250  0.375  0.500  0.250  0.250\n",
      "21 个特征按照accuracy进行排序\n",
      "knn             0.6875\n",
      "svm             0.6550\n",
      "gnb             0.6000\n",
      "tree            0.5925\n",
      "mbp             0.5875\n",
      "lda             0.5850\n",
      "RandomForest    0.5800\n",
      "glm             0.5625\n",
      "qda             0.4975\n",
      "ada             0.4550\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.625  0.875  0.875  0.750  1.000  0.750  0.625\n",
      "1  0.750  0.625  0.750         0.625  0.750  0.750  0.750  0.750  0.625  0.625\n",
      "2  0.625  0.625  0.750         0.625  0.750  0.750  0.625  0.625  0.625  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.625  0.500  0.625  0.625  0.500\n",
      "4  0.625  0.625  0.750         0.625  0.750  0.625  0.500  0.500  0.625  0.500\n",
      "5  0.500  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.500  0.500\n",
      "6  0.500  0.625  0.625         0.600  0.625  0.600  0.500  0.500  0.500  0.500\n",
      "7  0.500  0.500  0.500         0.500  0.500  0.500  0.500  0.500  0.400  0.375\n",
      "8  0.375  0.500  0.500         0.500  0.500  0.500  0.375  0.500  0.250  0.300\n",
      "9  0.375  0.375  0.300         0.500  0.500  0.250  0.125  0.500  0.250  0.250\n",
      "22 个特征按照accuracy进行排序\n",
      "knn             0.6625\n",
      "svm             0.6550\n",
      "lda             0.6100\n",
      "gnb             0.6000\n",
      "tree            0.5875\n",
      "RandomForest    0.5850\n",
      "glm             0.5750\n",
      "mbp             0.5150\n",
      "qda             0.5125\n",
      "ada             0.4800\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.750  0.875         0.875  0.875  0.875  0.875  1.000  0.5  0.625\n",
      "1  0.750  0.750  0.750         0.875  0.750  0.750  0.800  0.750  0.5  0.625\n",
      "2  0.625  0.625  0.750         0.750  0.750  0.625  0.750  0.625  0.5  0.500\n",
      "3  0.625  0.625  0.750         0.750  0.750  0.625  0.625  0.625  0.5  0.500\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.625  0.500  0.5  0.500\n",
      "5  0.625  0.500  0.750         0.625  0.625  0.600  0.500  0.500  0.5  0.500\n",
      "6  0.500  0.500  0.500         0.500  0.500  0.500  0.500  0.500  0.5  0.375\n",
      "7  0.500  0.500  0.500         0.500  0.500  0.500  0.375  0.500  0.5  0.375\n",
      "8  0.375  0.375  0.400         0.500  0.500  0.500  0.375  0.500  0.5  0.300\n",
      "9  0.250  0.375  0.375         0.375  0.500  0.250  0.375  0.500  0.5  0.250\n",
      "23 个特征按照accuracy进行排序\n",
      "svm             0.6400\n",
      "knn             0.6375\n",
      "RandomForest    0.6375\n",
      "gnb             0.6000\n",
      "lda             0.5850\n",
      "qda             0.5800\n",
      "glm             0.5750\n",
      "tree            0.5625\n",
      "mbp             0.5000\n",
      "ada             0.4550\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:718: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.750  0.875  0.875  0.625  1.000  0.875  0.625\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.625  0.750  0.750  0.625\n",
      "2  0.625  0.750  0.750         0.625  0.750  0.625  0.625  0.625  0.750  0.625\n",
      "3  0.625  0.700  0.750         0.625  0.625  0.625  0.600  0.625  0.625  0.500\n",
      "4  0.625  0.625  0.750         0.500  0.625  0.625  0.500  0.500  0.625  0.500\n",
      "5  0.625  0.500  0.750         0.500  0.625  0.625  0.500  0.500  0.625  0.500\n",
      "6  0.600  0.500  0.500         0.500  0.500  0.625  0.500  0.500  0.625  0.500\n",
      "7  0.500  0.500  0.500         0.500  0.500  0.600  0.500  0.500  0.625  0.400\n",
      "8  0.375  0.500  0.375         0.400  0.400  0.500  0.375  0.500  0.500  0.375\n",
      "9  0.250  0.500  0.300         0.375  0.375  0.375  0.375  0.500  0.375  0.125\n",
      "24 个特征按照accuracy进行排序\n",
      "mbp             0.6375\n",
      "svm             0.6300\n",
      "lda             0.6225\n",
      "tree            0.6075\n",
      "knn             0.6025\n",
      "gnb             0.6000\n",
      "glm             0.5850\n",
      "RandomForest    0.5525\n",
      "qda             0.5225\n",
      "ada             0.4775\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.750  0.875         0.875  0.875  0.875  0.750  1.000  0.5  0.875\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.625  0.750  0.5  0.750\n",
      "2  0.625  0.625  0.750         0.750  0.625  0.625  0.625  0.625  0.5  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.625  0.625  0.625  0.625  0.5  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "5  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "6  0.600  0.600  0.500         0.600  0.625  0.600  0.500  0.500  0.5  0.500\n",
      "7  0.500  0.500  0.500         0.500  0.625  0.500  0.500  0.500  0.5  0.500\n",
      "8  0.375  0.500  0.375         0.500  0.500  0.500  0.500  0.500  0.5  0.375\n",
      "9  0.250  0.500  0.300         0.375  0.500  0.375  0.375  0.500  0.5  0.125\n",
      "25 个特征按照accuracy进行排序\n",
      "knn             0.6375\n",
      "svm             0.6300\n",
      "RandomForest    0.6225\n",
      "lda             0.6100\n",
      "tree            0.6100\n",
      "gnb             0.6000\n",
      "glm             0.5850\n",
      "qda             0.5500\n",
      "ada             0.5375\n",
      "mbp             0.5000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.875  0.875  0.875  0.875  1.000  0.750  0.875\n",
      "1  0.750  0.750  0.750         0.750  0.875  0.750  0.750  0.750  0.750  0.750\n",
      "2  0.625  0.750  0.750         0.625  0.750  0.625  0.625  0.625  0.750  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.625  0.625  0.625  0.750  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.625  0.500  0.625  0.500\n",
      "5  0.625  0.625  0.750         0.500  0.625  0.625  0.500  0.500  0.625  0.500\n",
      "6  0.625  0.625  0.500         0.500  0.625  0.600  0.500  0.500  0.500  0.500\n",
      "7  0.600  0.500  0.500         0.400  0.500  0.500  0.500  0.500  0.500  0.500\n",
      "8  0.375  0.500  0.375         0.375  0.500  0.500  0.375  0.500  0.500  0.375\n",
      "9  0.375  0.400  0.300         0.375  0.400  0.375  0.250  0.500  0.300  0.125\n",
      "26 个特征按照accuracy进行排序\n",
      "knn             0.6525\n",
      "svm             0.6300\n",
      "tree            0.6150\n",
      "lda             0.6100\n",
      "glm             0.6100\n",
      "mbp             0.6050\n",
      "gnb             0.6000\n",
      "RandomForest    0.5650\n",
      "qda             0.5625\n",
      "ada             0.5375\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.875  0.875  0.875  0.875  1.000  0.875  0.750\n",
      "1  0.750  0.750  0.750         0.750  0.875  0.750  0.625  0.750  0.750  0.625\n",
      "2  0.625  0.750  0.750         0.625  0.750  0.625  0.625  0.625  0.750  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.625  0.625  0.625  0.625  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.750  0.625  0.625  0.500  0.500  0.500\n",
      "5  0.625  0.625  0.750         0.625  0.625  0.600  0.500  0.500  0.500  0.500\n",
      "6  0.600  0.500  0.500         0.500  0.625  0.500  0.500  0.500  0.500  0.500\n",
      "7  0.500  0.500  0.500         0.500  0.625  0.500  0.500  0.500  0.500  0.500\n",
      "8  0.375  0.500  0.375         0.500  0.500  0.500  0.500  0.500  0.375  0.375\n",
      "9  0.250  0.500  0.300         0.400  0.400  0.375  0.250  0.500  0.250  0.125\n",
      "27 个特征按照accuracy进行排序\n",
      "knn             0.6775\n",
      "svm             0.6300\n",
      "tree            0.6125\n",
      "RandomForest    0.6025\n",
      "gnb             0.6000\n",
      "lda             0.5975\n",
      "glm             0.5850\n",
      "mbp             0.5625\n",
      "qda             0.5625\n",
      "ada             0.5125\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb    mbp    ada\n",
      "0  0.875  0.750  0.875         0.875  0.875  0.875  0.875  1.000  0.750  0.625\n",
      "1  0.750  0.750  0.750         0.750  0.875  0.750  0.750  0.750  0.750  0.625\n",
      "2  0.625  0.625  0.750         0.750  0.750  0.625  0.625  0.625  0.750  0.625\n",
      "3  0.625  0.625  0.750         0.750  0.750  0.625  0.625  0.625  0.750  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.750  0.625  0.625  0.500  0.625  0.625\n",
      "5  0.625  0.500  0.750         0.625  0.750  0.625  0.500  0.500  0.625  0.600\n",
      "6  0.625  0.500  0.500         0.600  0.625  0.600  0.500  0.500  0.600  0.500\n",
      "7  0.500  0.500  0.500         0.500  0.625  0.500  0.375  0.500  0.500  0.500\n",
      "8  0.250  0.400  0.375         0.500  0.500  0.500  0.250  0.500  0.375  0.375\n",
      "9  0.250  0.375  0.200         0.375  0.400  0.375  0.125  0.500  0.375  0.375\n",
      "28 个特征按照accuracy进行排序\n",
      "knn             0.6900\n",
      "RandomForest    0.6350\n",
      "svm             0.6200\n",
      "mbp             0.6100\n",
      "lda             0.6100\n",
      "gnb             0.6000\n",
      "glm             0.5750\n",
      "tree            0.5650\n",
      "ada             0.5475\n",
      "qda             0.5250\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.750  0.750  0.750         0.750  0.750  0.750  0.750  1.000  0.5  0.625\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.750  0.750  0.5  0.625\n",
      "2  0.625  0.750  0.750         0.750  0.625  0.750  0.750  0.625  0.5  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.625  0.625  0.625  0.625  0.5  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "5  0.625  0.625  0.625         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "6  0.500  0.600  0.500         0.625  0.625  0.600  0.375  0.500  0.5  0.375\n",
      "7  0.500  0.500  0.375         0.625  0.500  0.500  0.375  0.500  0.5  0.375\n",
      "8  0.500  0.500  0.375         0.500  0.500  0.375  0.375  0.500  0.5  0.375\n",
      "9  0.250  0.500  0.300         0.500  0.400  0.375  0.125  0.500  0.5  0.250\n",
      "29 个特征按照accuracy进行排序\n",
      "RandomForest    0.6375\n",
      "tree            0.6225\n",
      "knn             0.6025\n",
      "gnb             0.6000\n",
      "lda             0.5975\n",
      "svm             0.5925\n",
      "glm             0.5750\n",
      "qda             0.5125\n",
      "mbp             0.5000\n",
      "ada             0.4875\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.750  0.750  0.875         0.750  0.750  0.750  0.750  1.000  0.5  0.750\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.625  0.750  0.5  0.625\n",
      "2  0.625  0.625  0.750         0.750  0.625  0.625  0.625  0.625  0.5  0.625\n",
      "3  0.625  0.625  0.750         0.750  0.625  0.625  0.625  0.625  0.5  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.625\n",
      "5  0.625  0.600  0.625         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "6  0.500  0.500  0.500         0.625  0.625  0.600  0.375  0.500  0.5  0.400\n",
      "7  0.500  0.500  0.375         0.500  0.500  0.500  0.375  0.500  0.5  0.375\n",
      "8  0.500  0.500  0.375         0.500  0.500  0.375  0.125  0.500  0.5  0.250\n",
      "9  0.375  0.500  0.300         0.400  0.400  0.375  0.125  0.500  0.5  0.250\n",
      "30 个特征按照accuracy进行排序\n",
      "RandomForest    0.6275\n",
      "svm             0.6050\n",
      "knn             0.6025\n",
      "gnb             0.6000\n",
      "tree            0.5975\n",
      "glm             0.5875\n",
      "lda             0.5850\n",
      "ada             0.5025\n",
      "mbp             0.5000\n",
      "qda             0.4625\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.750  0.750         0.750  0.750  0.750  0.500  1.000  0.5  0.750\n",
      "1  0.750  0.625  0.750         0.750  0.750  0.750  0.500  0.750  0.5  0.625\n",
      "2  0.625  0.625  0.750         0.625  0.625  0.750  0.500  0.625  0.5  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.625  0.750  0.500  0.625  0.5  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.700  0.500  0.500  0.5  0.625\n",
      "5  0.625  0.500  0.625         0.625  0.625  0.625  0.375  0.500  0.5  0.500\n",
      "6  0.625  0.500  0.500         0.500  0.625  0.625  0.375  0.500  0.5  0.400\n",
      "7  0.500  0.500  0.375         0.500  0.500  0.500  0.375  0.500  0.5  0.375\n",
      "8  0.500  0.500  0.375         0.500  0.400  0.500  0.375  0.500  0.5  0.250\n",
      "9  0.375  0.400  0.300         0.375  0.375  0.375  0.125  0.500  0.5  0.250\n",
      "31 个特征按照accuracy进行排序\n",
      "lda             0.6325\n",
      "glm             0.6125\n",
      "gnb             0.6000\n",
      "svm             0.5925\n",
      "knn             0.5900\n",
      "RandomForest    0.5875\n",
      "tree            0.5650\n",
      "ada             0.5025\n",
      "mbp             0.5000\n",
      "qda             0.4125\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.750  0.750         0.750  0.750  0.750  0.625  1.000  0.5  0.750\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.500  0.750  0.5  0.625\n",
      "2  0.625  0.625  0.750         0.750  0.750  0.750  0.500  0.625  0.5  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.700  0.500  0.625  0.5  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.625\n",
      "5  0.625  0.625  0.625         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "6  0.500  0.500  0.500         0.625  0.625  0.500  0.500  0.500  0.5  0.400\n",
      "7  0.500  0.500  0.375         0.500  0.625  0.500  0.375  0.500  0.5  0.375\n",
      "8  0.500  0.500  0.375         0.500  0.375  0.500  0.375  0.500  0.5  0.250\n",
      "9  0.375  0.400  0.300         0.250  0.300  0.375  0.125  0.500  0.5  0.250\n",
      "32 个特征按照accuracy进行排序\n",
      "knn             0.6175\n",
      "lda             0.6075\n",
      "gnb             0.6000\n",
      "RandomForest    0.6000\n",
      "glm             0.6000\n",
      "svm             0.5925\n",
      "tree            0.5900\n",
      "ada             0.5025\n",
      "mbp             0.5000\n",
      "qda             0.4500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for k in range(31):\n",
    "    selectkBest=SelectKBest(f_classif,k=k+2)\n",
    " \n",
    "    # 选择自变量\n",
    " \n",
    "    feature=X\n",
    " \n",
    "    # 调用fit方法进行最好特征的选择\n",
    " \n",
    "    bestFeature=selectkBest.fit_transform(feature, Y)\n",
    " \n",
    "    # 查看关键因子\n",
    "    #print(selectkBest.get_support())\n",
    "    #print(feature.columns[selectkBest.get_support()])\n",
    "    #for i in range(30):\n",
    "    x = X[feature.columns[selectkBest.get_support()]]\n",
    "    metric_all = pd.DataFrame()\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "    lr = LogisticRegression(C=1000, solver='liblinear', random_state=0)\n",
    "    metric = cross_val_score(lr, x, Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['glm'] = metric[::-1]\n",
    " \n",
    "    # 拟合决策树模型\n",
    "    from sklearn import tree\n",
    " \n",
    "    tree = tree.DecisionTreeClassifier(criterion='gini')\n",
    "    metric = cross_val_score(tree, x, Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['tree'] = metric[::-1]\n",
    " \n",
    "    # 拟合svm模型\n",
    "    from sklearn import svm\n",
    " \n",
    "    svc = svm.SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "    metric = cross_val_score(svc, x, Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['svm'] = metric[::-1]\n",
    " \n",
    "    # 拟合随机森林算法\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "    RF = RandomForestClassifier(n_estimators=30, criterion='gini', random_state=10)\n",
    "    metric = cross_val_score(RF, x, Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['RandomForest'] = metric[::-1]\n",
    " \n",
    "    # 构造knn最近邻模型\n",
    "    from sklearn import neighbors\n",
    " \n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree')\n",
    "    metric = cross_val_score(estimator=knn, X=x, y=Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['knn'] = metric[::-1]\n",
    " \n",
    "    # 构造lda模型\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    " \n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=None, priors=None)\n",
    "    metric = cross_val_score(estimator=lda, X=x, y=Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['lda'] = metric[::-1]\n",
    " \n",
    "    # 构造qda模型\n",
    "    from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    " \n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    metric = cross_val_score(estimator=qda, X=x, y=Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['qda'] = metric[::-1]\n",
    " \n",
    "    #  高斯朴素贝叶斯,多项式贝叶斯适用于文本分类，伯努利贝叶斯需要全部变量威二值变量\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    " \n",
    "    gnb = GaussianNB()\n",
    "    metric = cross_val_score(estimator=gnb, X=x, y=Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['gnb'] = metric[::-1]\n",
    " \n",
    "    # sklearn提供了bp多层神经网络，隐含层设为 (4, 3, 2)\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    " \n",
    "    mbp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(4, 3, 2), random_state=1)\n",
    "    metric = cross_val_score(estimator=mbp, X=x, y=Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['mbp'] = metric[::-1]\n",
    " \n",
    "    # 采用adaboost算法\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    " \n",
    "    # 弱分类器的参数 base_estimator 默认为决策树\n",
    "    ada = AdaBoostClassifier(n_estimators=100)\n",
    "    metric = cross_val_score(estimator=ada, X=x, y=Y, cv=10, scoring='accuracy')\n",
    "    metric.sort()\n",
    "    metric_all['ada'] = metric[::-1]\n",
    " \n",
    "    # 将10种模型结果进行比较\n",
    "    print(metric_all)\n",
    "    print(k+2,\"个特征按照accuracy进行排序\")\n",
    "    metric_mean = metric_all.mean()\n",
    "    print(metric_mean.sort_values(ascending=False))\n",
    "    #score = cross_val_score(g, X[feature.columns[selectkBest.get_support()]], Y, cv=10, scoring='accuracy')\n",
    "    #print(k, score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     glm   tree    svm  RandomForest    knn    lda    qda    gnb  mbp    ada\n",
      "0  0.875  0.750  0.750         0.750  0.750  0.750  0.625  1.000  0.5  0.750\n",
      "1  0.750  0.750  0.750         0.750  0.750  0.750  0.500  0.750  0.5  0.625\n",
      "2  0.625  0.750  0.750         0.750  0.750  0.750  0.500  0.625  0.5  0.625\n",
      "3  0.625  0.625  0.750         0.625  0.750  0.700  0.500  0.625  0.5  0.625\n",
      "4  0.625  0.625  0.750         0.625  0.625  0.625  0.500  0.500  0.5  0.625\n",
      "5  0.625  0.500  0.625         0.625  0.625  0.625  0.500  0.500  0.5  0.500\n",
      "6  0.500  0.500  0.500         0.625  0.625  0.500  0.500  0.500  0.5  0.400\n",
      "7  0.500  0.500  0.375         0.500  0.625  0.500  0.375  0.500  0.5  0.375\n",
      "8  0.500  0.500  0.375         0.500  0.375  0.500  0.375  0.500  0.5  0.250\n",
      "9  0.375  0.500  0.300         0.250  0.300  0.375  0.125  0.500  0.5  0.250\n",
      "按照accuracy进行排序\n",
      "knn             0.6175\n",
      "lda             0.6075\n",
      "gnb             0.6000\n",
      "RandomForest    0.6000\n",
      "tree            0.6000\n",
      "glm             0.6000\n",
      "svm             0.5925\n",
      "ada             0.5025\n",
      "mbp             0.5000\n",
      "qda             0.4500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "metric_all = pd.DataFrame()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "lr = LogisticRegression(C=1000, solver='liblinear', random_state=0)\n",
    "metric = cross_val_score(lr, X, Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['glm'] = metric[::-1]\n",
    " \n",
    "# 拟合决策树模型\n",
    "from sklearn import tree\n",
    " \n",
    "tree = tree.DecisionTreeClassifier(criterion='gini')\n",
    "metric = cross_val_score(tree, X, Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['tree'] = metric[::-1]\n",
    " \n",
    "# 拟合svm模型\n",
    "from sklearn import svm\n",
    " \n",
    "svc = svm.SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "metric = cross_val_score(svc, X, Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['svm'] = metric[::-1]\n",
    " \n",
    "# 拟合随机森林算法\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "RF = RandomForestClassifier(n_estimators=30, criterion='gini', random_state=10)\n",
    "metric = cross_val_score(RF, X, Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['RandomForest'] = metric[::-1]\n",
    " \n",
    "# 构造knn最近邻模型\n",
    "from sklearn import neighbors\n",
    " \n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree')\n",
    "metric = cross_val_score(estimator=knn, X=X, y=Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['knn'] = metric[::-1]\n",
    " \n",
    "# 构造lda模型\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    " \n",
    "lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=None, priors=None)\n",
    "metric = cross_val_score(estimator=lda, X=X, y=Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['lda'] = metric[::-1]\n",
    " \n",
    "# 构造qda模型\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    " \n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "metric = cross_val_score(estimator=qda, X=X, y=Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['qda'] = metric[::-1]\n",
    " \n",
    "#  高斯朴素贝叶斯,多项式贝叶斯适用于文本分类，伯努利贝叶斯需要全部变量威二值变量\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    " \n",
    "gnb = GaussianNB()\n",
    "metric = cross_val_score(estimator=gnb, X=X, y=Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['gnb'] = metric[::-1]\n",
    " \n",
    "# sklearn提供了bp多层神经网络，隐含层设为 (4, 3, 2)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    " \n",
    "mbp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(4, 3, 2), random_state=1)\n",
    "metric = cross_val_score(estimator=mbp, X=X, y=Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['mbp'] = metric[::-1]\n",
    " \n",
    "# 采用adaboost算法\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    " \n",
    "# 弱分类器的参数 base_estimator 默认为决策树\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "metric = cross_val_score(estimator=ada, X=X, y=Y, cv=10, scoring='accuracy')\n",
    "metric.sort()\n",
    "metric_all['ada'] = metric[::-1]\n",
    " \n",
    "# 将10种模型结果进行比较\n",
    "print(metric_all)\n",
    "print(\"按照accuracy进行排序\")\n",
    "metric_mean = metric_all.mean()\n",
    "print(metric_mean.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
